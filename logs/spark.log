2024-06-10T14:49:54,857 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T14:49:55,779 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T14:49:55,780 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T14:49:55,780 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T14:49:55,815 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T14:49:55,816 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T14:49:55,817 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T14:49:55,818 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry
2024-06-10T14:49:55,845 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T14:49:55,855 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T14:49:55,856 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T14:49:55,918 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T14:49:55,919 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T14:49:55,920 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T14:49:55,920 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T14:49:55,921 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T14:49:56,146 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 34933.
2024-06-10T14:49:56,175 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T14:49:56,226 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T14:49:56,251 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T14:49:56,252 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T14:49:56,259 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T14:49:56,288 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-9cf9a0a7-27a5-4943-bc0a-65996a077eae
2024-06-10T14:49:56,305 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T14:49:56,325 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T14:49:56,374 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @2715ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T14:49:56,459 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T14:49:56,470 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T14:49:56,495 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @2836ms
2024-06-10T14:49:56,546 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@4b656ab4{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T14:49:56,546 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T14:49:56,568 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3ef36d05{/,null,AVAILABLE,@Spark}
2024-06-10T14:49:56,589 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/delta-core_2.12-2.2.0.jar at spark://bca62233ef54:34933/jars/delta-core_2.12-2.2.0.jar with timestamp 1718030995773
2024-06-10T14:49:56,589 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://bca62233ef54:34933/jars/hadoop-aws-3.3.2.jar with timestamp 1718030995773
2024-06-10T14:49:56,590 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/delta-storage-2.2.0.jar at spark://bca62233ef54:34933/jars/delta-storage-2.2.0.jar with timestamp 1718030995773
2024-06-10T14:49:56,590 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://bca62233ef54:34933/jars/aws-java-sdk-1.12.367.jar with timestamp 1718030995773
2024-06-10T14:49:56,590 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://bca62233ef54:34933/jars/s3-2.18.41.jar with timestamp 1718030995773
2024-06-10T14:49:56,590 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://bca62233ef54:34933/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718030995773
2024-06-10T14:49:56,685 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T14:49:56,748 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.20.0.2:7077 after 33 ms (0 ms spent in bootstraps)
2024-06-10T14:49:56,845 [dispatcher-event-loop-0] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610144956-0002
2024-06-10T14:49:56,857 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38519.
2024-06-10T14:49:56,858 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on bca62233ef54:38519
2024-06-10T14:49:56,861 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T14:49:56,854 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610144956-0002/0 on worker-20240610141054-172.20.0.5-34579 (172.20.0.5:34579) with 2 core(s)
2024-06-10T14:49:56,870 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610144956-0002/0 on hostPort 172.20.0.5:34579 with 2 core(s), 3.0 GiB RAM
2024-06-10T14:49:56,870 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610144956-0002/1 on worker-20240610141054-172.20.0.4-34547 (172.20.0.4:34547) with 2 core(s)
2024-06-10T14:49:56,871 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610144956-0002/1 on hostPort 172.20.0.4:34547 with 2 core(s), 3.0 GiB RAM
2024-06-10T14:49:56,871 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610144956-0002/2 on worker-20240610141054-172.20.0.6-45681 (172.20.0.6:45681) with 2 core(s)
2024-06-10T14:49:56,871 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610144956-0002/2 on hostPort 172.20.0.6:45681 with 2 core(s), 3.0 GiB RAM
2024-06-10T14:49:56,883 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, bca62233ef54, 38519, None)
2024-06-10T14:49:56,890 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager bca62233ef54:38519 with 434.4 MiB RAM, BlockManagerId(driver, bca62233ef54, 38519, None)
2024-06-10T14:49:56,899 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, bca62233ef54, 38519, None)
2024-06-10T14:49:56,902 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, bca62233ef54, 38519, None)
2024-06-10T14:49:56,926 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610144956-0002/2 is now RUNNING
2024-06-10T14:49:56,951 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610144956-0002/1 is now RUNNING
2024-06-10T14:49:56,951 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610144956-0002/0 is now RUNNING
2024-06-10T14:49:57,123 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610144956-0002.inprogress
2024-06-10T14:49:57,398 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@3ef36d05{/,null,STOPPED,@Spark}
2024-06-10T14:49:57,399 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@74aae49b{/jobs,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,400 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30d179ea{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,401 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5c6f10b{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,402 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4bdecb90{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,403 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5969a2de{/stages,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,404 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f72e40e{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,406 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@409c99d{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,408 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1ab8b7eb{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,410 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ee940e3{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,413 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@193c27ce{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,415 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@28632bbc{/storage,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,417 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@302559c3{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,429 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@21c705d7{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,432 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@b73c181{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,433 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4589f889{/environment,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,435 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@52aa74da{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,473 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@49be9e62{/executors,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,476 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@9e1b7c6{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,485 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3cb90ed0{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,487 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5013749c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,489 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6bc6785f{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,491 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@31d12528{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,525 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1fd15f98{/static,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,540 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@69d2a592{/,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,546 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@36828275{/api,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,561 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@34d7e2a4{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,565 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3e7e3e17{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,582 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7499527c{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T14:49:57,585 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T14:49:59,618 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-10T15:47:19,035 [Thread-5] WARN  org.apache.spark.sql.catalyst.util.SparkStringUtils [] - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2024-06-10T15:47:19,040 [Thread-5] WARN  ch.cern.sparkmeasure.StageMetrics [] - Stage metrics data refreshed into temp view PerfStageMetrics
2024-06-10T15:47:19,631 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-10T15:47:21,522 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-10T17:17:27,851 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T17:17:29,255 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T17:17:29,256 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T17:17:29,256 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T17:17:29,285 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T17:17:29,285 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T17:17:29,286 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T17:17:29,286 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq
2024-06-10T17:17:29,311 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T17:17:29,319 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T17:17:29,320 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T17:17:29,389 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T17:17:29,390 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T17:17:29,390 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T17:17:29,391 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T17:17:29,391 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T17:17:29,637 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 44569.
2024-06-10T17:17:29,674 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T17:17:29,728 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T17:17:29,765 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T17:17:29,766 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T17:17:29,774 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T17:17:29,805 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-14d3f4bd-d205-42c2-b1d3-c094e663b756
2024-06-10T17:17:29,828 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T17:17:29,854 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T17:17:29,915 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @4173ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T17:17:30,005 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T17:17:30,020 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T17:17:30,044 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @4303ms
2024-06-10T17:17:30,085 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@4b656ab4{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T17:17:30,085 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T17:17:30,118 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3ef36d05{/,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,134 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/delta-core_2.12-2.2.0.jar at spark://bca62233ef54:44569/jars/delta-core_2.12-2.2.0.jar with timestamp 1718039849248
2024-06-10T17:17:30,134 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://bca62233ef54:44569/jars/hadoop-aws-3.3.2.jar with timestamp 1718039849248
2024-06-10T17:17:30,135 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/delta-storage-2.2.0.jar at spark://bca62233ef54:44569/jars/delta-storage-2.2.0.jar with timestamp 1718039849248
2024-06-10T17:17:30,135 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://bca62233ef54:44569/jars/aws-java-sdk-1.12.367.jar with timestamp 1718039849248
2024-06-10T17:17:30,135 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://bca62233ef54:44569/jars/s3-2.18.41.jar with timestamp 1718039849248
2024-06-10T17:17:30,136 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://bca62233ef54:44569/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718039849248
2024-06-10T17:17:30,239 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T17:17:30,283 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.20.0.2:7077 after 25 ms (0 ms spent in bootstraps)
2024-06-10T17:17:30,372 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610171730-0003
2024-06-10T17:17:30,383 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610171730-0003/0 on worker-20240610141054-172.20.0.5-34579 (172.20.0.5:34579) with 2 core(s)
2024-06-10T17:17:30,388 [dispatcher-event-loop-0] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610171730-0003/0 on hostPort 172.20.0.5:34579 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:17:30,388 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610171730-0003/1 on worker-20240610141054-172.20.0.4-34547 (172.20.0.4:34547) with 2 core(s)
2024-06-10T17:17:30,391 [dispatcher-event-loop-0] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610171730-0003/1 on hostPort 172.20.0.4:34547 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:17:30,392 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610171730-0003/2 on worker-20240610141054-172.20.0.6-45681 (172.20.0.6:45681) with 2 core(s)
2024-06-10T17:17:30,393 [dispatcher-event-loop-0] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610171730-0003/2 on hostPort 172.20.0.6:45681 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:17:30,396 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39653.
2024-06-10T17:17:30,397 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on bca62233ef54:39653
2024-06-10T17:17:30,403 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T17:17:30,433 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, bca62233ef54, 39653, None)
2024-06-10T17:17:30,440 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager bca62233ef54:39653 with 434.4 MiB RAM, BlockManagerId(driver, bca62233ef54, 39653, None)
2024-06-10T17:17:30,444 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, bca62233ef54, 39653, None)
2024-06-10T17:17:30,448 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, bca62233ef54, 39653, None)
2024-06-10T17:17:30,626 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610171730-0003.inprogress
2024-06-10T17:17:30,754 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610171730-0003/0 is now RUNNING
2024-06-10T17:17:30,805 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@3ef36d05{/,null,STOPPED,@Spark}
2024-06-10T17:17:30,807 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@74aae49b{/jobs,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,809 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30d179ea{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,810 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5c6f10b{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,812 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4bdecb90{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,813 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5969a2de{/stages,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,815 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f72e40e{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,817 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@409c99d{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,819 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1ab8b7eb{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,821 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ee940e3{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,823 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@193c27ce{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,825 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@28632bbc{/storage,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,826 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@302559c3{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,828 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@21c705d7{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,830 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@b73c181{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,832 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4589f889{/environment,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,834 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@52aa74da{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,836 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@49be9e62{/executors,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,838 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@9e1b7c6{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,840 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3cb90ed0{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,850 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5013749c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,868 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6bc6785f{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,870 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@31d12528{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,909 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1fd15f98{/static,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,923 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@69d2a592{/,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,927 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@36828275{/api,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,931 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@34d7e2a4{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,933 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3e7e3e17{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,946 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7499527c{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T17:17:30,948 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T17:17:31,082 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610171730-0003/1 is now RUNNING
2024-06-10T17:17:31,129 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610171730-0003/2 is now RUNNING
2024-06-10T17:17:34,178 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-10T17:22:23,353 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T17:22:24,215 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T17:22:24,216 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T17:22:24,216 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T17:22:24,243 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T17:22:24,244 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T17:22:24,244 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T17:22:24,244 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq
2024-06-10T17:22:24,269 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T17:22:24,278 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T17:22:24,279 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T17:22:24,339 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T17:22:24,339 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T17:22:24,340 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T17:22:24,340 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T17:22:24,341 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T17:22:24,531 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 40345.
2024-06-10T17:22:24,553 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T17:22:24,599 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T17:22:24,619 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T17:22:24,620 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T17:22:24,625 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T17:22:24,651 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-43dc9075-64af-46c0-8bb1-d63cbbdbae7b
2024-06-10T17:22:24,665 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T17:22:24,687 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T17:22:24,731 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @2617ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T17:22:24,808 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T17:22:24,819 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T17:22:24,839 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @2725ms
2024-06-10T17:22:24,895 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@4b656ab4{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T17:22:24,895 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T17:22:24,920 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3ef36d05{/,null,AVAILABLE,@Spark}
2024-06-10T17:22:24,940 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/delta-core_2.12-2.2.0.jar at spark://bca62233ef54:40345/jars/delta-core_2.12-2.2.0.jar with timestamp 1718040144210
2024-06-10T17:22:24,941 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://bca62233ef54:40345/jars/hadoop-aws-3.3.2.jar with timestamp 1718040144210
2024-06-10T17:22:24,942 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/delta-storage-2.2.0.jar at spark://bca62233ef54:40345/jars/delta-storage-2.2.0.jar with timestamp 1718040144210
2024-06-10T17:22:24,943 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://bca62233ef54:40345/jars/aws-java-sdk-1.12.367.jar with timestamp 1718040144210
2024-06-10T17:22:24,944 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://bca62233ef54:40345/jars/s3-2.18.41.jar with timestamp 1718040144210
2024-06-10T17:22:24,946 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://bca62233ef54:40345/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718040144210
2024-06-10T17:22:25,040 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T17:22:25,091 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.20.0.2:7077 after 29 ms (0 ms spent in bootstraps)
2024-06-10T17:22:25,179 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610172225-0004
2024-06-10T17:22:25,183 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610172225-0004/0 on worker-20240610141054-172.20.0.5-34579 (172.20.0.5:34579) with 2 core(s)
2024-06-10T17:22:25,186 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610172225-0004/0 on hostPort 172.20.0.5:34579 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:22:25,187 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610172225-0004/1 on worker-20240610141054-172.20.0.4-34547 (172.20.0.4:34547) with 2 core(s)
2024-06-10T17:22:25,188 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610172225-0004/1 on hostPort 172.20.0.4:34547 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:22:25,201 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610172225-0004/2 on worker-20240610141054-172.20.0.6-45681 (172.20.0.6:45681) with 2 core(s)
2024-06-10T17:22:25,205 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610172225-0004/2 on hostPort 172.20.0.6:45681 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:22:25,214 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42505.
2024-06-10T17:22:25,215 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on bca62233ef54:42505
2024-06-10T17:22:25,220 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T17:22:25,248 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, bca62233ef54, 42505, None)
2024-06-10T17:22:25,257 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager bca62233ef54:42505 with 434.4 MiB RAM, BlockManagerId(driver, bca62233ef54, 42505, None)
2024-06-10T17:22:25,264 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, bca62233ef54, 42505, None)
2024-06-10T17:22:25,270 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, bca62233ef54, 42505, None)
2024-06-10T17:22:25,303 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610172225-0004/1 is now RUNNING
2024-06-10T17:22:25,317 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610172225-0004/2 is now RUNNING
2024-06-10T17:22:25,505 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610172225-0004.inprogress
2024-06-10T17:22:25,808 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@3ef36d05{/,null,STOPPED,@Spark}
2024-06-10T17:22:25,810 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@74aae49b{/jobs,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,812 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30d179ea{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,814 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5c6f10b{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,816 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4bdecb90{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,818 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5969a2de{/stages,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,824 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f72e40e{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,841 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@409c99d{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,843 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1ab8b7eb{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,845 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ee940e3{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,848 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@193c27ce{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,869 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@28632bbc{/storage,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,872 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@302559c3{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,879 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@21c705d7{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,886 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@b73c181{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,891 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4589f889{/environment,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,895 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@52aa74da{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,899 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@49be9e62{/executors,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,904 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@9e1b7c6{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,909 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3cb90ed0{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,912 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5013749c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,918 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6bc6785f{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,923 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@31d12528{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,947 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1fd15f98{/static,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,951 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@69d2a592{/,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,965 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@36828275{/api,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,970 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@34d7e2a4{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T17:22:25,980 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3e7e3e17{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T17:22:26,002 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7499527c{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T17:22:26,007 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T17:22:26,079 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610172225-0004/0 is now RUNNING
2024-06-10T17:22:28,039 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-10T17:25:09,576 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T17:25:10,476 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T17:25:10,476 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T17:25:10,477 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T17:25:10,504 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T17:25:10,504 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T17:25:10,505 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T17:25:10,505 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq
2024-06-10T17:25:10,524 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T17:25:10,532 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T17:25:10,534 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T17:25:10,582 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T17:25:10,583 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T17:25:10,583 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T17:25:10,583 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T17:25:10,584 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T17:25:10,770 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 37671.
2024-06-10T17:25:10,801 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T17:25:10,843 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T17:25:10,862 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T17:25:10,863 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T17:25:10,869 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T17:25:10,897 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-85f667ad-f6f2-4ed4-80a7-c29b20f35af5
2024-06-10T17:25:10,915 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T17:25:10,935 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T17:25:10,978 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @2665ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T17:25:11,061 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T17:25:11,074 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T17:25:11,099 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @2786ms
2024-06-10T17:25:11,147 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@4b656ab4{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T17:25:11,148 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T17:25:11,169 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3ef36d05{/,null,AVAILABLE,@Spark}
2024-06-10T17:25:11,188 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/delta-core_2.12-2.2.0.jar at spark://bca62233ef54:37671/jars/delta-core_2.12-2.2.0.jar with timestamp 1718040310470
2024-06-10T17:25:11,189 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://bca62233ef54:37671/jars/hadoop-aws-3.3.2.jar with timestamp 1718040310470
2024-06-10T17:25:11,189 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/delta-storage-2.2.0.jar at spark://bca62233ef54:37671/jars/delta-storage-2.2.0.jar with timestamp 1718040310470
2024-06-10T17:25:11,189 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://bca62233ef54:37671/jars/aws-java-sdk-1.12.367.jar with timestamp 1718040310470
2024-06-10T17:25:11,190 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://bca62233ef54:37671/jars/s3-2.18.41.jar with timestamp 1718040310470
2024-06-10T17:25:11,190 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://bca62233ef54:37671/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718040310470
2024-06-10T17:25:11,282 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T17:25:11,333 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.20.0.2:7077 after 28 ms (0 ms spent in bootstraps)
2024-06-10T17:25:11,422 [dispatcher-event-loop-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610172511-0005
2024-06-10T17:25:11,425 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610172511-0005/0 on worker-20240610141054-172.20.0.5-34579 (172.20.0.5:34579) with 2 core(s)
2024-06-10T17:25:11,429 [dispatcher-event-loop-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610172511-0005/0 on hostPort 172.20.0.5:34579 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:25:11,435 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610172511-0005/1 on worker-20240610141054-172.20.0.4-34547 (172.20.0.4:34547) with 2 core(s)
2024-06-10T17:25:11,436 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610172511-0005/1 on hostPort 172.20.0.4:34547 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:25:11,438 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610172511-0005/2 on worker-20240610141054-172.20.0.6-45681 (172.20.0.6:45681) with 2 core(s)
2024-06-10T17:25:11,439 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610172511-0005/2 on hostPort 172.20.0.6:45681 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:25:11,440 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40729.
2024-06-10T17:25:11,440 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on bca62233ef54:40729
2024-06-10T17:25:11,444 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T17:25:11,464 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, bca62233ef54, 40729, None)
2024-06-10T17:25:11,471 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager bca62233ef54:40729 with 434.4 MiB RAM, BlockManagerId(driver, bca62233ef54, 40729, None)
2024-06-10T17:25:11,475 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, bca62233ef54, 40729, None)
2024-06-10T17:25:11,477 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, bca62233ef54, 40729, None)
2024-06-10T17:25:11,668 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610172511-0005/0 is now RUNNING
2024-06-10T17:25:11,731 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610172511-0005.inprogress
2024-06-10T17:25:11,966 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610172511-0005/1 is now RUNNING
2024-06-10T17:25:12,008 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610172511-0005/2 is now RUNNING
2024-06-10T17:25:12,047 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@3ef36d05{/,null,STOPPED,@Spark}
2024-06-10T17:25:12,049 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@74aae49b{/jobs,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,050 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30d179ea{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,052 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5c6f10b{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,057 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4bdecb90{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,058 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5969a2de{/stages,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,060 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f72e40e{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,092 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@409c99d{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,094 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1ab8b7eb{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,098 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ee940e3{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,100 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@193c27ce{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,102 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@28632bbc{/storage,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,104 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@302559c3{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,106 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@21c705d7{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,108 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@b73c181{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,116 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4589f889{/environment,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,119 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@52aa74da{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,121 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@49be9e62{/executors,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,124 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@9e1b7c6{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,127 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3cb90ed0{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,132 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5013749c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,135 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6bc6785f{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,137 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@31d12528{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,151 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1fd15f98{/static,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,155 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@69d2a592{/,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,161 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@36828275{/api,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,163 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@34d7e2a4{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,164 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3e7e3e17{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,181 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7499527c{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T17:25:12,183 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T17:25:14,340 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-10T17:27:08,174 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T17:27:09,079 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T17:27:09,080 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T17:27:09,081 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T17:27:09,107 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T17:27:09,108 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T17:27:09,108 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T17:27:09,109 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq
2024-06-10T17:27:09,135 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T17:27:09,144 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T17:27:09,146 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T17:27:09,196 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T17:27:09,197 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T17:27:09,197 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T17:27:09,197 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T17:27:09,198 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T17:27:09,384 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 46655.
2024-06-10T17:27:09,413 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T17:27:09,453 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T17:27:09,474 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T17:27:09,475 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T17:27:09,482 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T17:27:09,505 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-79e9a535-d280-4813-9709-6649329304c1
2024-06-10T17:27:09,523 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T17:27:09,545 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T17:27:09,586 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @2722ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T17:27:09,678 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T17:27:09,700 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T17:27:09,735 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @2872ms
2024-06-10T17:27:09,788 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@75bf5c3a{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T17:27:09,788 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T17:27:09,815 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@523ad056{/,null,AVAILABLE,@Spark}
2024-06-10T17:27:09,836 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/delta-core_2.12-2.2.0.jar at spark://d0f692dbcdd2:46655/jars/delta-core_2.12-2.2.0.jar with timestamp 1718040429074
2024-06-10T17:27:09,837 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://d0f692dbcdd2:46655/jars/hadoop-aws-3.3.2.jar with timestamp 1718040429074
2024-06-10T17:27:09,837 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/delta-storage-2.2.0.jar at spark://d0f692dbcdd2:46655/jars/delta-storage-2.2.0.jar with timestamp 1718040429074
2024-06-10T17:27:09,837 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://d0f692dbcdd2:46655/jars/aws-java-sdk-1.12.367.jar with timestamp 1718040429074
2024-06-10T17:27:09,837 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://d0f692dbcdd2:46655/jars/s3-2.18.41.jar with timestamp 1718040429074
2024-06-10T17:27:09,838 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://d0f692dbcdd2:46655/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718040429074
2024-06-10T17:27:09,931 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T17:27:09,982 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.21.0.2:7077 after 28 ms (0 ms spent in bootstraps)
2024-06-10T17:27:10,132 [dispatcher-event-loop-0] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610172710-0000
2024-06-10T17:27:10,141 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36267.
2024-06-10T17:27:10,142 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on d0f692dbcdd2:36267
2024-06-10T17:27:10,144 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T17:27:10,158 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, d0f692dbcdd2, 36267, None)
2024-06-10T17:27:10,165 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager d0f692dbcdd2:36267 with 434.4 MiB RAM, BlockManagerId(driver, d0f692dbcdd2, 36267, None)
2024-06-10T17:27:10,172 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, d0f692dbcdd2, 36267, None)
2024-06-10T17:27:10,179 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, d0f692dbcdd2, 36267, None)
2024-06-10T17:27:10,181 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610172710-0000/0 on worker-20240610172701-172.21.0.7-46467 (172.21.0.7:46467) with 2 core(s)
2024-06-10T17:27:10,189 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610172710-0000/0 on hostPort 172.21.0.7:46467 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:27:10,192 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610172710-0000/1 on worker-20240610172701-172.21.0.5-34017 (172.21.0.5:34017) with 2 core(s)
2024-06-10T17:27:10,195 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610172710-0000/1 on hostPort 172.21.0.5:34017 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:27:10,217 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610172710-0000/2 on worker-20240610172701-172.21.0.6-46147 (172.21.0.6:46147) with 2 core(s)
2024-06-10T17:27:10,219 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610172710-0000/2 on hostPort 172.21.0.6:46147 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:27:10,525 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610172710-0000.inprogress
2024-06-10T17:27:10,547 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610172710-0000/2 is now RUNNING
2024-06-10T17:27:10,549 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610172710-0000/1 is now RUNNING
2024-06-10T17:27:10,552 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610172710-0000/0 is now RUNNING
2024-06-10T17:27:10,722 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@523ad056{/,null,STOPPED,@Spark}
2024-06-10T17:27:10,724 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6fdb580d{/jobs,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,725 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6dd36892{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,727 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7800d121{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,749 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3cab3a63{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,761 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@41c2f078{/stages,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,763 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@22abb136{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,779 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4e78c78{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,781 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@12a3a730{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,795 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2060da8a{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,801 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@f81e054{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,815 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@51baa95d{/storage,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,818 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7365d596{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,821 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@44c7de91{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,825 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5a31b398{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,834 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7b2c7d81{/environment,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,852 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3a0986c{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,855 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@32f7c60b{/executors,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,865 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@332f5be8{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,869 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6e2fb4c8{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,878 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4d00c072{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,883 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1bb33083{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,885 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1d578099{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,903 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5dec4755{/static,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,930 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@51dc41cc{/,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,934 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@31c72fe8{/api,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,936 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@44a36545{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,940 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2b6163b9{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,958 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@19d0b2cb{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T17:27:10,970 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T17:27:13,261 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-10T17:36:19,106 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T17:36:19,972 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T17:36:19,972 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T17:36:19,973 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T17:36:20,001 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T17:36:20,001 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T17:36:20,002 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T17:36:20,002 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq
2024-06-10T17:36:20,023 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T17:36:20,033 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T17:36:20,035 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T17:36:20,090 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T17:36:20,091 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T17:36:20,092 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T17:36:20,092 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T17:36:20,093 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T17:36:20,270 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 35597.
2024-06-10T17:36:20,296 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T17:36:20,336 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T17:36:20,356 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T17:36:20,357 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T17:36:20,362 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T17:36:20,387 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-ef312654-d367-4e59-831c-c91d200f6b05
2024-06-10T17:36:20,404 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T17:36:20,423 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T17:36:20,471 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @2626ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T17:36:20,548 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T17:36:20,558 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T17:36:20,582 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @2738ms
2024-06-10T17:36:20,631 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@2d8a3d90{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T17:36:20,631 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T17:36:20,652 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2edbd2f6{/,null,AVAILABLE,@Spark}
2024-06-10T17:36:20,672 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://601fd26cc72d:35597/jars/hadoop-aws-3.3.2.jar with timestamp 1718040979966
2024-06-10T17:36:20,673 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://601fd26cc72d:35597/jars/aws-java-sdk-1.12.367.jar with timestamp 1718040979966
2024-06-10T17:36:20,673 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://601fd26cc72d:35597/jars/s3-2.18.41.jar with timestamp 1718040979966
2024-06-10T17:36:20,673 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://601fd26cc72d:35597/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718040979966
2024-06-10T17:36:20,758 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T17:36:20,806 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.22.0.2:7077 after 26 ms (0 ms spent in bootstraps)
2024-06-10T17:36:20,951 [dispatcher-event-loop-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610173620-0000
2024-06-10T17:36:20,962 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38223.
2024-06-10T17:36:20,963 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 601fd26cc72d:38223
2024-06-10T17:36:20,966 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T17:36:20,984 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 601fd26cc72d, 38223, None)
2024-06-10T17:36:20,995 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 601fd26cc72d:38223 with 434.4 MiB RAM, BlockManagerId(driver, 601fd26cc72d, 38223, None)
2024-06-10T17:36:21,000 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 601fd26cc72d, 38223, None)
2024-06-10T17:36:21,002 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 601fd26cc72d, 38223, None)
2024-06-10T17:36:21,018 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610173620-0000/0 on worker-20240610173515-172.22.0.6-40655 (172.22.0.6:40655) with 2 core(s)
2024-06-10T17:36:21,027 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610173620-0000/0 on hostPort 172.22.0.6:40655 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:36:21,034 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610173620-0000/1 on worker-20240610173514-172.22.0.5-43309 (172.22.0.5:43309) with 2 core(s)
2024-06-10T17:36:21,037 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610173620-0000/1 on hostPort 172.22.0.5:43309 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:36:21,045 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610173620-0000/2 on worker-20240610173514-172.22.0.4-43383 (172.22.0.4:43383) with 2 core(s)
2024-06-10T17:36:21,047 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610173620-0000/2 on hostPort 172.22.0.4:43383 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:36:21,300 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610173620-0000.inprogress
2024-06-10T17:36:21,404 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610173620-0000/1 is now RUNNING
2024-06-10T17:36:21,411 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610173620-0000/0 is now RUNNING
2024-06-10T17:36:21,417 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610173620-0000/2 is now RUNNING
2024-06-10T17:36:21,581 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@2edbd2f6{/,null,STOPPED,@Spark}
2024-06-10T17:36:21,587 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6efe5013{/jobs,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,593 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3e63c104{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,595 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6b95580e{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,596 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@62cd218c{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,598 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1e6692c6{/stages,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,601 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1c73d0a{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,603 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@44662cd3{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,605 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4664d706{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,606 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6c49808e{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,610 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@485f1551{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,613 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@10c8f2b9{/storage,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,615 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@11026923{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,618 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5c79b76c{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,633 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@47c0da6a{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,638 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@43797b34{/environment,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,640 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@86c0eb5{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,641 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@149cd15{/executors,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,653 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5448a654{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,655 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1f7d3aee{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,657 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7aad0975{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,659 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@478dd3b6{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,666 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@d251bb6{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,690 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1cdcf236{/static,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,712 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6da42aea{/,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,719 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2953b260{/api,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,725 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1f529c11{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,727 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5d316a3{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,754 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@49168fc8{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T17:36:21,757 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T17:36:24,143 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-10T17:51:30,143 [Thread-5] WARN  org.apache.spark.sql.catalyst.util.SparkStringUtils [] - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2024-06-10T17:51:30,150 [Thread-5] WARN  ch.cern.sparkmeasure.StageMetrics [] - Stage metrics data refreshed into temp view PerfStageMetrics
2024-06-10T17:51:30,541 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-10T17:51:31,963 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-10T17:55:54,453 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T17:55:55,639 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T17:55:55,639 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T17:55:55,640 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T17:55:55,668 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T17:55:55,668 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T17:55:55,669 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T17:55:55,669 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq-spark-measure
2024-06-10T17:55:55,698 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T17:55:55,707 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T17:55:55,708 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T17:55:55,782 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T17:55:55,783 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T17:55:55,783 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T17:55:55,784 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T17:55:55,784 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T17:55:56,010 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 40595.
2024-06-10T17:55:56,052 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T17:55:56,101 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T17:55:56,126 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T17:55:56,127 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T17:55:56,136 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T17:55:56,161 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-9d37143e-dceb-4baa-a11e-27bf154ab5a4
2024-06-10T17:55:56,179 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T17:55:56,196 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T17:55:56,255 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3696ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T17:55:56,344 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T17:55:56,358 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T17:55:56,388 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @3829ms
2024-06-10T17:55:56,442 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@13f48729{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T17:55:56,442 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T17:55:56,469 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5283d231{/,null,AVAILABLE,@Spark}
2024-06-10T17:55:56,490 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://601fd26cc72d:40595/jars/hadoop-aws-3.3.2.jar with timestamp 1718042155633
2024-06-10T17:55:56,490 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://601fd26cc72d:40595/jars/aws-java-sdk-1.12.367.jar with timestamp 1718042155633
2024-06-10T17:55:56,491 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://601fd26cc72d:40595/jars/s3-2.18.41.jar with timestamp 1718042155633
2024-06-10T17:55:56,491 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://601fd26cc72d:40595/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718042155633
2024-06-10T17:55:56,593 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T17:55:56,645 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.22.0.2:7077 after 29 ms (0 ms spent in bootstraps)
2024-06-10T17:55:56,765 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610175556-0001
2024-06-10T17:55:56,773 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38821.
2024-06-10T17:55:56,773 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 601fd26cc72d:38821
2024-06-10T17:55:56,776 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T17:55:56,792 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610175556-0001/0 on worker-20240610173515-172.22.0.6-40655 (172.22.0.6:40655) with 2 core(s)
2024-06-10T17:55:56,796 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 601fd26cc72d, 38821, None)
2024-06-10T17:55:56,800 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610175556-0001/0 on hostPort 172.22.0.6:40655 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:55:56,802 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610175556-0001/1 on worker-20240610173514-172.22.0.5-43309 (172.22.0.5:43309) with 2 core(s)
2024-06-10T17:55:56,804 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610175556-0001/1 on hostPort 172.22.0.5:43309 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:55:56,805 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610175556-0001/2 on worker-20240610173514-172.22.0.4-43383 (172.22.0.4:43383) with 2 core(s)
2024-06-10T17:55:56,806 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610175556-0001/2 on hostPort 172.22.0.4:43383 with 2 core(s), 3.0 GiB RAM
2024-06-10T17:55:56,807 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 601fd26cc72d:38821 with 434.4 MiB RAM, BlockManagerId(driver, 601fd26cc72d, 38821, None)
2024-06-10T17:55:56,811 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 601fd26cc72d, 38821, None)
2024-06-10T17:55:56,814 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 601fd26cc72d, 38821, None)
2024-06-10T17:55:56,972 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610175556-0001.inprogress
2024-06-10T17:55:57,119 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@5283d231{/,null,STOPPED,@Spark}
2024-06-10T17:55:57,121 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1847fb72{/jobs,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,122 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ee1af97{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,123 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3fb5b776{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,124 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@47b6f381{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,125 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30b7ac12{/stages,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,126 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@16fa06e2{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,128 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@185c11b5{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,130 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@945d51{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,132 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@77a899a8{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,135 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@736618ee{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,137 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4033778b{/storage,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,138 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7250f8f{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,140 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1e5187a{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,141 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@54da4c1c{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,144 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2aaf66aa{/environment,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,147 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@34cbd6e5{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,152 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6264f111{/executors,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,154 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4b93b16{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,155 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@8294cba{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,158 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@569fd968{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,160 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f594315{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,162 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@75108119{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,180 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@41363418{/static,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,182 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@58e4e569{/,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,189 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7f3296e4{/api,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,192 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2455b2c7{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,195 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4694af3b{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,204 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@164030a8{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T17:55:57,214 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T17:55:57,311 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610175556-0001/1 is now RUNNING
2024-06-10T17:55:57,327 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610175556-0001/0 is now RUNNING
2024-06-10T17:55:57,342 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610175556-0001/2 is now RUNNING
2024-06-10T17:56:00,072 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-10T18:10:24,887 [Thread-5] WARN  org.apache.spark.sql.catalyst.util.SparkStringUtils [] - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2024-06-10T18:10:24,908 [Thread-5] WARN  ch.cern.sparkmeasure.StageMetrics [] - Stage metrics data refreshed into temp view PerfStageMetrics
2024-06-10T18:30:58,247 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T18:30:59,393 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T18:30:59,394 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T18:30:59,394 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T18:30:59,423 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T18:30:59,423 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T18:30:59,424 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T18:30:59,424 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq-fine-tuning
2024-06-10T18:30:59,448 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T18:30:59,456 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T18:30:59,458 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T18:30:59,530 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T18:30:59,530 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T18:30:59,531 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T18:30:59,531 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T18:30:59,532 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T18:30:59,776 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 34033.
2024-06-10T18:30:59,820 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T18:30:59,869 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T18:30:59,895 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T18:30:59,896 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T18:30:59,902 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T18:30:59,928 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-326f6404-5e09-4b2d-93f4-9bfda813be66
2024-06-10T18:30:59,947 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T18:30:59,966 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T18:31:00,036 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3609ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T18:31:00,135 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T18:31:00,148 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T18:31:00,175 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @3750ms
2024-06-10T18:31:00,226 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@13f48729{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T18:31:00,226 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T18:31:00,251 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5283d231{/,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,267 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://601fd26cc72d:34033/jars/hadoop-aws-3.3.2.jar with timestamp 1718044259386
2024-06-10T18:31:00,268 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://601fd26cc72d:34033/jars/aws-java-sdk-1.12.367.jar with timestamp 1718044259386
2024-06-10T18:31:00,268 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://601fd26cc72d:34033/jars/s3-2.18.41.jar with timestamp 1718044259386
2024-06-10T18:31:00,268 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://601fd26cc72d:34033/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718044259386
2024-06-10T18:31:00,367 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T18:31:00,422 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.22.0.2:7077 after 28 ms (0 ms spent in bootstraps)
2024-06-10T18:31:00,540 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610183100-0002
2024-06-10T18:31:00,560 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35873.
2024-06-10T18:31:00,560 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 601fd26cc72d:35873
2024-06-10T18:31:00,563 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T18:31:00,574 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610183100-0002/0 on worker-20240610173515-172.22.0.6-40655 (172.22.0.6:40655) with 2 core(s)
2024-06-10T18:31:00,577 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610183100-0002/0 on hostPort 172.22.0.6:40655 with 2 core(s), 3.0 GiB RAM
2024-06-10T18:31:00,579 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610183100-0002/1 on worker-20240610173514-172.22.0.5-43309 (172.22.0.5:43309) with 2 core(s)
2024-06-10T18:31:00,582 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610183100-0002/1 on hostPort 172.22.0.5:43309 with 2 core(s), 3.0 GiB RAM
2024-06-10T18:31:00,583 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610183100-0002/2 on worker-20240610173514-172.22.0.4-43383 (172.22.0.4:43383) with 2 core(s)
2024-06-10T18:31:00,585 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610183100-0002/2 on hostPort 172.22.0.4:43383 with 2 core(s), 3.0 GiB RAM
2024-06-10T18:31:00,587 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 601fd26cc72d, 35873, None)
2024-06-10T18:31:00,591 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 601fd26cc72d:35873 with 434.4 MiB RAM, BlockManagerId(driver, 601fd26cc72d, 35873, None)
2024-06-10T18:31:00,595 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 601fd26cc72d, 35873, None)
2024-06-10T18:31:00,597 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 601fd26cc72d, 35873, None)
2024-06-10T18:31:00,767 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610183100-0002.inprogress
2024-06-10T18:31:00,906 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@5283d231{/,null,STOPPED,@Spark}
2024-06-10T18:31:00,907 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1847fb72{/jobs,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,909 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ee1af97{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,914 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3fb5b776{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,916 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@47b6f381{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,918 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30b7ac12{/stages,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,920 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@16fa06e2{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,923 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@185c11b5{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,926 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@945d51{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,929 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@77a899a8{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,935 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@736618ee{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,939 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4033778b{/storage,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,941 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7250f8f{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,944 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1e5187a{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,946 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@54da4c1c{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,949 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2aaf66aa{/environment,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,952 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@34cbd6e5{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,956 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6264f111{/executors,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,958 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4b93b16{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,961 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@8294cba{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,963 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@569fd968{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,965 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f594315{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,967 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@75108119{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,989 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@41363418{/static,null,AVAILABLE,@Spark}
2024-06-10T18:31:00,991 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@58e4e569{/,null,AVAILABLE,@Spark}
2024-06-10T18:31:01,006 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7f3296e4{/api,null,AVAILABLE,@Spark}
2024-06-10T18:31:01,011 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2455b2c7{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T18:31:01,012 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4694af3b{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T18:31:01,025 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@164030a8{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T18:31:01,028 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T18:31:01,104 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610183100-0002/1 is now RUNNING
2024-06-10T18:31:01,164 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610183100-0002/0 is now RUNNING
2024-06-10T18:31:01,281 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610183100-0002/2 is now RUNNING
2024-06-10T18:36:18,024 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T18:36:18,907 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T18:36:18,908 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T18:36:18,908 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T18:36:18,936 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T18:36:18,936 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T18:36:18,937 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T18:36:18,937 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq-fine-tuning
2024-06-10T18:36:18,959 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T18:36:18,966 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T18:36:18,968 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T18:36:19,023 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T18:36:19,024 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T18:36:19,024 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T18:36:19,025 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T18:36:19,025 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T18:36:19,204 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 38481.
2024-06-10T18:36:19,227 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T18:36:19,268 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T18:36:19,286 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T18:36:19,287 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T18:36:19,291 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T18:36:19,310 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-6adc7837-aa31-49f9-bb2f-6a20b24f2313
2024-06-10T18:36:19,323 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T18:36:19,340 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T18:36:19,382 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @2604ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T18:36:19,456 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T18:36:19,466 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T18:36:19,487 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @2710ms
2024-06-10T18:36:19,532 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@13f48729{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T18:36:19,533 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T18:36:19,560 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5283d231{/,null,AVAILABLE,@Spark}
2024-06-10T18:36:19,576 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://601fd26cc72d:38481/jars/hadoop-aws-3.3.2.jar with timestamp 1718044578902
2024-06-10T18:36:19,577 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://601fd26cc72d:38481/jars/aws-java-sdk-1.12.367.jar with timestamp 1718044578902
2024-06-10T18:36:19,577 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://601fd26cc72d:38481/jars/s3-2.18.41.jar with timestamp 1718044578902
2024-06-10T18:36:19,578 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://601fd26cc72d:38481/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718044578902
2024-06-10T18:36:19,670 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T18:36:19,712 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.22.0.2:7077 after 25 ms (0 ms spent in bootstraps)
2024-06-10T18:36:19,799 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610183619-0003
2024-06-10T18:36:19,802 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610183619-0003/0 on worker-20240610173515-172.22.0.6-40655 (172.22.0.6:40655) with 2 core(s)
2024-06-10T18:36:19,805 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610183619-0003/0 on hostPort 172.22.0.6:40655 with 2 core(s), 3.0 GiB RAM
2024-06-10T18:36:19,815 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35041.
2024-06-10T18:36:19,816 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 601fd26cc72d:35041
2024-06-10T18:36:19,820 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T18:36:19,824 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610183619-0003/1 on worker-20240610173514-172.22.0.5-43309 (172.22.0.5:43309) with 2 core(s)
2024-06-10T18:36:19,833 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610183619-0003/1 on hostPort 172.22.0.5:43309 with 2 core(s), 3.0 GiB RAM
2024-06-10T18:36:19,844 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610183619-0003/2 on worker-20240610173514-172.22.0.4-43383 (172.22.0.4:43383) with 2 core(s)
2024-06-10T18:36:19,847 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610183619-0003/2 on hostPort 172.22.0.4:43383 with 2 core(s), 3.0 GiB RAM
2024-06-10T18:36:19,848 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 601fd26cc72d, 35041, None)
2024-06-10T18:36:19,859 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 601fd26cc72d:35041 with 434.4 MiB RAM, BlockManagerId(driver, 601fd26cc72d, 35041, None)
2024-06-10T18:36:19,871 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 601fd26cc72d, 35041, None)
2024-06-10T18:36:19,874 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 601fd26cc72d, 35041, None)
2024-06-10T18:36:19,902 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610183619-0003/0 is now RUNNING
2024-06-10T18:36:19,921 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610183619-0003/1 is now RUNNING
2024-06-10T18:36:19,968 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610183619-0003/2 is now RUNNING
2024-06-10T18:36:20,098 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610183619-0003.inprogress
2024-06-10T18:36:20,328 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@5283d231{/,null,STOPPED,@Spark}
2024-06-10T18:36:20,348 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1847fb72{/jobs,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,351 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ee1af97{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,354 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3fb5b776{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,393 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@47b6f381{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,394 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30b7ac12{/stages,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,396 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@16fa06e2{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,407 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@185c11b5{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,426 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@945d51{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,428 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@77a899a8{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,434 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@736618ee{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,442 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4033778b{/storage,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,446 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7250f8f{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,451 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1e5187a{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,478 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@54da4c1c{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,481 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2aaf66aa{/environment,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,485 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@34cbd6e5{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,493 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6264f111{/executors,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,499 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4b93b16{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,504 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@8294cba{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,509 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@569fd968{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,530 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f594315{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,533 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@75108119{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,558 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@41363418{/static,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,561 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@58e4e569{/,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,584 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7f3296e4{/api,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,587 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2455b2c7{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,591 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4694af3b{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,614 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@164030a8{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T18:36:20,616 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T18:36:22,716 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-10T18:50:55,137 [Thread-5] WARN  org.apache.spark.sql.catalyst.util.SparkStringUtils [] - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2024-06-10T18:50:55,163 [Thread-5] WARN  ch.cern.sparkmeasure.StageMetrics [] - Stage metrics data refreshed into temp view PerfStageMetrics
2024-06-10T18:50:55,540 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-10T18:50:57,063 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-10T18:52:41,825 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T18:52:43,031 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T18:52:43,031 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T18:52:43,032 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T18:52:43,063 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T18:52:43,063 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T18:52:43,064 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T18:52:43,064 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq-fine-tuning
2024-06-10T18:52:43,088 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 512, script: , vendor: , memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T18:52:43,097 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T18:52:43,098 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T18:52:43,172 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T18:52:43,173 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T18:52:43,173 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T18:52:43,174 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T18:52:43,174 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T18:52:43,421 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 45927.
2024-06-10T18:52:43,465 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T18:52:43,519 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T18:52:43,548 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T18:52:43,549 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T18:52:43,553 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T18:52:43,581 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-527e2a25-88e1-4ee5-98c3-f30ca94d742b
2024-06-10T18:52:43,601 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T18:52:43,619 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T18:52:43,683 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3761ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T18:52:43,780 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T18:52:43,796 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T18:52:43,828 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @3907ms
2024-06-10T18:52:43,882 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@49ef94b3{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T18:52:43,882 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T18:52:43,909 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7e9145a0{/,null,AVAILABLE,@Spark}
2024-06-10T18:52:43,925 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://601fd26cc72d:45927/jars/hadoop-aws-3.3.2.jar with timestamp 1718045563023
2024-06-10T18:52:43,926 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://601fd26cc72d:45927/jars/aws-java-sdk-1.12.367.jar with timestamp 1718045563023
2024-06-10T18:52:43,927 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://601fd26cc72d:45927/jars/s3-2.18.41.jar with timestamp 1718045563023
2024-06-10T18:52:43,927 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://601fd26cc72d:45927/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718045563023
2024-06-10T18:52:44,025 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T18:52:44,075 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.22.0.2:7077 after 27 ms (0 ms spent in bootstraps)
2024-06-10T18:52:44,302 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610185244-0004
2024-06-10T18:52:44,310 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36803.
2024-06-10T18:52:44,310 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 601fd26cc72d:36803
2024-06-10T18:52:44,313 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T18:52:44,325 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 601fd26cc72d, 36803, None)
2024-06-10T18:52:44,330 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 601fd26cc72d:36803 with 434.4 MiB RAM, BlockManagerId(driver, 601fd26cc72d, 36803, None)
2024-06-10T18:52:44,333 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 601fd26cc72d, 36803, None)
2024-06-10T18:52:44,335 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 601fd26cc72d, 36803, None)
2024-06-10T18:52:44,335 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610185244-0004/0 on worker-20240610173515-172.22.0.6-40655 (172.22.0.6:40655) with 2 core(s)
2024-06-10T18:52:44,344 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610185244-0004/0 on hostPort 172.22.0.6:40655 with 2 core(s), 3.0 GiB RAM
2024-06-10T18:52:44,345 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610185244-0004/1 on worker-20240610173514-172.22.0.5-43309 (172.22.0.5:43309) with 2 core(s)
2024-06-10T18:52:44,346 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610185244-0004/1 on hostPort 172.22.0.5:43309 with 2 core(s), 3.0 GiB RAM
2024-06-10T18:52:44,348 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610185244-0004/2 on worker-20240610173514-172.22.0.4-43383 (172.22.0.4:43383) with 2 core(s)
2024-06-10T18:52:44,349 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610185244-0004/2 on hostPort 172.22.0.4:43383 with 2 core(s), 3.0 GiB RAM
2024-06-10T18:52:44,510 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610185244-0004.inprogress
2024-06-10T18:52:44,645 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@7e9145a0{/,null,STOPPED,@Spark}
2024-06-10T18:52:44,647 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30d179ea{/jobs,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,650 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4d53ef6b{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,652 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4bdecb90{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,653 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5969a2de{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,654 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f72e40e{/stages,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,656 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@a0dbc86{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,658 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1ab8b7eb{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,660 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ee940e3{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,662 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@193c27ce{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,665 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@28632bbc{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,667 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@302559c3{/storage,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,669 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@21c705d7{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,670 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@b73c181{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,672 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4589f889{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,674 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@52aa74da{/environment,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,677 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@49be9e62{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,681 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@9e1b7c6{/executors,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,683 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3cb90ed0{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,685 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5013749c{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,688 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6bc6785f{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,691 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@31d12528{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,695 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1fd15f98{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,715 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@35e5875f{/static,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,717 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@36828275{/,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,722 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@11a6fcf9{/api,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,725 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3e7e3e17{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,729 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@141b8f9d{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,740 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@56600838{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T18:52:44,743 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T18:52:44,978 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610185244-0004/1 is now RUNNING
2024-06-10T18:52:45,021 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610185244-0004/0 is now RUNNING
2024-06-10T18:52:45,088 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610185244-0004/2 is now RUNNING
2024-06-10T18:52:47,520 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-10T19:08:27,767 [Thread-5] WARN  org.apache.spark.sql.catalyst.util.SparkStringUtils [] - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2024-06-10T19:08:27,791 [Thread-5] WARN  ch.cern.sparkmeasure.StageMetrics [] - Stage metrics data refreshed into temp view PerfStageMetrics
2024-06-10T19:08:28,129 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-10T19:08:29,232 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-10T19:53:48,488 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T19:53:49,830 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T19:53:49,831 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T19:53:49,831 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T19:53:49,861 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T19:53:49,862 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T19:53:49,863 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T19:53:49,864 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: yelp-data-json-to-parquet
2024-06-10T19:53:49,890 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T19:53:49,899 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T19:53:49,900 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T19:53:49,973 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T19:53:49,974 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T19:53:49,975 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T19:53:49,975 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T19:53:49,975 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T19:53:50,227 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 39135.
2024-06-10T19:53:50,277 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T19:53:50,333 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T19:53:50,361 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T19:53:50,362 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T19:53:50,368 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T19:53:50,397 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-8605098e-1bd0-4b5b-8163-b880ff798dcd
2024-06-10T19:53:50,418 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T19:53:50,435 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T19:53:50,502 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @4109ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T19:53:50,607 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T19:53:50,620 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T19:53:50,641 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @4248ms
2024-06-10T19:53:50,700 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@13f48729{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T19:53:50,700 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T19:53:50,724 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5283d231{/,null,AVAILABLE,@Spark}
2024-06-10T19:53:50,743 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://601fd26cc72d:39135/jars/hadoop-aws-3.3.2.jar with timestamp 1718049229822
2024-06-10T19:53:50,744 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://601fd26cc72d:39135/jars/aws-java-sdk-1.12.367.jar with timestamp 1718049229822
2024-06-10T19:53:50,744 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://601fd26cc72d:39135/jars/s3-2.18.41.jar with timestamp 1718049229822
2024-06-10T19:53:50,745 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://601fd26cc72d:39135/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718049229822
2024-06-10T19:53:50,832 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T19:53:50,884 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.22.0.2:7077 after 26 ms (0 ms spent in bootstraps)
2024-06-10T19:53:51,030 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610195350-0005
2024-06-10T19:53:51,038 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39511.
2024-06-10T19:53:51,038 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 601fd26cc72d:39511
2024-06-10T19:53:51,041 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T19:53:51,051 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 601fd26cc72d, 39511, None)
2024-06-10T19:53:51,054 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 601fd26cc72d:39511 with 434.4 MiB RAM, BlockManagerId(driver, 601fd26cc72d, 39511, None)
2024-06-10T19:53:51,056 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 601fd26cc72d, 39511, None)
2024-06-10T19:53:51,058 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 601fd26cc72d, 39511, None)
2024-06-10T19:53:51,072 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610195350-0005/0 on worker-20240610173515-172.22.0.6-40655 (172.22.0.6:40655) with 2 core(s)
2024-06-10T19:53:51,076 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610195350-0005/0 on hostPort 172.22.0.6:40655 with 2 core(s), 3.0 GiB RAM
2024-06-10T19:53:51,076 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610195350-0005/1 on worker-20240610173514-172.22.0.5-43309 (172.22.0.5:43309) with 2 core(s)
2024-06-10T19:53:51,078 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610195350-0005/1 on hostPort 172.22.0.5:43309 with 2 core(s), 3.0 GiB RAM
2024-06-10T19:53:51,079 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610195350-0005/2 on worker-20240610173514-172.22.0.4-43383 (172.22.0.4:43383) with 2 core(s)
2024-06-10T19:53:51,080 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610195350-0005/2 on hostPort 172.22.0.4:43383 with 2 core(s), 3.0 GiB RAM
2024-06-10T19:53:51,222 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610195350-0005.inprogress
2024-06-10T19:53:51,350 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@5283d231{/,null,STOPPED,@Spark}
2024-06-10T19:53:51,353 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1847fb72{/jobs,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,354 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ee1af97{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,356 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3fb5b776{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,359 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@47b6f381{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,360 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30b7ac12{/stages,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,362 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@16fa06e2{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,365 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@185c11b5{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,366 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@945d51{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,369 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@77a899a8{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,374 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@736618ee{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,378 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4033778b{/storage,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,382 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7250f8f{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,384 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1e5187a{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,390 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@54da4c1c{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,392 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2aaf66aa{/environment,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,395 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@34cbd6e5{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,397 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6264f111{/executors,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,400 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4b93b16{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,404 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@8294cba{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,407 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@569fd968{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,409 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f594315{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,411 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@75108119{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,428 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@41363418{/static,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,430 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@58e4e569{/,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,436 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7f3296e4{/api,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,439 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2455b2c7{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,441 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4694af3b{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,447 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@164030a8{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T19:53:51,448 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T19:53:51,875 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610195350-0005/1 is now RUNNING
2024-06-10T19:53:51,883 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610195350-0005/0 is now RUNNING
2024-06-10T19:53:55,990 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-10T19:56:04,932 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T19:56:06,108 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T19:56:06,109 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T19:56:06,110 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T19:56:06,149 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T19:56:06,150 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T19:56:06,151 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T19:56:06,151 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: yelp-data-json-to-parquet
2024-06-10T19:56:06,182 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T19:56:06,193 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T19:56:06,194 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T19:56:06,268 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T19:56:06,269 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T19:56:06,270 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T19:56:06,271 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T19:56:06,271 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T19:56:06,527 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 42991.
2024-06-10T19:56:06,572 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T19:56:06,614 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T19:56:06,637 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T19:56:06,639 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T19:56:06,644 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T19:56:06,668 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-6416e34d-5f51-4915-bdff-80440254807f
2024-06-10T19:56:06,685 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T19:56:06,705 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T19:56:06,762 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3785ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T19:56:06,858 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T19:56:06,877 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T19:56:06,908 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @3931ms
2024-06-10T19:56:06,969 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@13f48729{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T19:56:06,970 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T19:56:06,999 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5283d231{/,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,020 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://601fd26cc72d:42991/jars/hadoop-aws-3.3.2.jar with timestamp 1718049366096
2024-06-10T19:56:07,020 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://601fd26cc72d:42991/jars/aws-java-sdk-1.12.367.jar with timestamp 1718049366096
2024-06-10T19:56:07,020 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://601fd26cc72d:42991/jars/s3-2.18.41.jar with timestamp 1718049366096
2024-06-10T19:56:07,021 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://601fd26cc72d:42991/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718049366096
2024-06-10T19:56:07,118 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T19:56:07,168 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.22.0.2:7077 after 28 ms (0 ms spent in bootstraps)
2024-06-10T19:56:07,275 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610195607-0006
2024-06-10T19:56:07,278 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610195607-0006/0 on worker-20240610173515-172.22.0.6-40655 (172.22.0.6:40655) with 2 core(s)
2024-06-10T19:56:07,281 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610195607-0006/0 on hostPort 172.22.0.6:40655 with 2 core(s), 3.0 GiB RAM
2024-06-10T19:56:07,283 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610195607-0006/1 on worker-20240610173514-172.22.0.5-43309 (172.22.0.5:43309) with 2 core(s)
2024-06-10T19:56:07,284 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610195607-0006/1 on hostPort 172.22.0.5:43309 with 2 core(s), 3.0 GiB RAM
2024-06-10T19:56:07,286 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610195607-0006/2 on worker-20240610173514-172.22.0.4-43383 (172.22.0.4:43383) with 2 core(s)
2024-06-10T19:56:07,287 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610195607-0006/2 on hostPort 172.22.0.4:43383 with 2 core(s), 3.0 GiB RAM
2024-06-10T19:56:07,294 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40705.
2024-06-10T19:56:07,295 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 601fd26cc72d:40705
2024-06-10T19:56:07,305 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T19:56:07,326 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 601fd26cc72d, 40705, None)
2024-06-10T19:56:07,335 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 601fd26cc72d:40705 with 434.4 MiB RAM, BlockManagerId(driver, 601fd26cc72d, 40705, None)
2024-06-10T19:56:07,339 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 601fd26cc72d, 40705, None)
2024-06-10T19:56:07,341 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 601fd26cc72d, 40705, None)
2024-06-10T19:56:07,412 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610195607-0006/0 is now RUNNING
2024-06-10T19:56:07,420 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610195607-0006/1 is now RUNNING
2024-06-10T19:56:07,588 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610195607-0006/2 is now RUNNING
2024-06-10T19:56:07,606 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610195607-0006.inprogress
2024-06-10T19:56:07,859 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@5283d231{/,null,STOPPED,@Spark}
2024-06-10T19:56:07,880 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1847fb72{/jobs,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,882 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ee1af97{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,884 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3fb5b776{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,886 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@47b6f381{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,893 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30b7ac12{/stages,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,900 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@16fa06e2{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,915 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@185c11b5{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,934 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@945d51{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,936 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@77a899a8{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,937 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@736618ee{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,938 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4033778b{/storage,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,939 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7250f8f{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,941 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1e5187a{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,943 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@54da4c1c{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,975 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2aaf66aa{/environment,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,978 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@34cbd6e5{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,981 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6264f111{/executors,null,AVAILABLE,@Spark}
2024-06-10T19:56:07,983 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4b93b16{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T19:56:08,004 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@8294cba{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T19:56:08,006 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@569fd968{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T19:56:08,009 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f594315{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T19:56:08,011 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@75108119{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T19:56:08,052 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@41363418{/static,null,AVAILABLE,@Spark}
2024-06-10T19:56:08,077 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@58e4e569{/,null,AVAILABLE,@Spark}
2024-06-10T19:56:08,081 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7f3296e4{/api,null,AVAILABLE,@Spark}
2024-06-10T19:56:08,082 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2455b2c7{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T19:56:08,084 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4694af3b{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T19:56:08,108 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@164030a8{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T19:56:08,117 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T19:56:11,163 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-10T20:19:54,039 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T20:19:55,279 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T20:19:55,280 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T20:19:55,281 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T20:19:55,310 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T20:19:55,310 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T20:19:55,311 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T20:19:55,311 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: yelp-data-json-to-parquet
2024-06-10T20:19:55,336 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T20:19:55,346 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T20:19:55,347 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T20:19:55,422 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T20:19:55,422 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T20:19:55,423 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T20:19:55,424 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T20:19:55,424 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T20:19:55,678 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 34225.
2024-06-10T20:19:55,722 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T20:19:55,771 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T20:19:55,798 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T20:19:55,798 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T20:19:55,804 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T20:19:55,837 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-88a295b8-b27e-45f6-976c-5c50167257f2
2024-06-10T20:19:55,855 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T20:19:55,878 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T20:19:55,944 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3935ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T20:19:56,040 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T20:19:56,056 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T20:19:56,082 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @4074ms
2024-06-10T20:19:56,135 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@55038c09{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T20:19:56,135 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T20:19:56,163 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@67b12933{/,null,AVAILABLE,@Spark}
2024-06-10T20:19:56,181 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://601fd26cc72d:34225/jars/hadoop-aws-3.3.2.jar with timestamp 1718050795272
2024-06-10T20:19:56,181 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://601fd26cc72d:34225/jars/aws-java-sdk-1.12.367.jar with timestamp 1718050795272
2024-06-10T20:19:56,182 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://601fd26cc72d:34225/jars/s3-2.18.41.jar with timestamp 1718050795272
2024-06-10T20:19:56,183 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://601fd26cc72d:34225/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718050795272
2024-06-10T20:19:56,281 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T20:19:56,337 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.22.0.2:7077 after 28 ms (0 ms spent in bootstraps)
2024-06-10T20:19:56,491 [dispatcher-event-loop-0] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610201956-0007
2024-06-10T20:19:56,498 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41573.
2024-06-10T20:19:56,498 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 601fd26cc72d:41573
2024-06-10T20:19:56,500 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T20:19:56,514 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610201956-0007/0 on worker-20240610173515-172.22.0.6-40655 (172.22.0.6:40655) with 2 core(s)
2024-06-10T20:19:56,513 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 601fd26cc72d, 41573, None)
2024-06-10T20:19:56,518 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610201956-0007/0 on hostPort 172.22.0.6:40655 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:19:56,518 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610201956-0007/1 on worker-20240610173514-172.22.0.5-43309 (172.22.0.5:43309) with 2 core(s)
2024-06-10T20:19:56,519 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610201956-0007/1 on hostPort 172.22.0.5:43309 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:19:56,521 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610201956-0007/2 on worker-20240610173514-172.22.0.4-43383 (172.22.0.4:43383) with 2 core(s)
2024-06-10T20:19:56,524 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610201956-0007/2 on hostPort 172.22.0.4:43383 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:19:56,526 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 601fd26cc72d:41573 with 434.4 MiB RAM, BlockManagerId(driver, 601fd26cc72d, 41573, None)
2024-06-10T20:19:56,530 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 601fd26cc72d, 41573, None)
2024-06-10T20:19:56,532 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 601fd26cc72d, 41573, None)
2024-06-10T20:19:56,771 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610201956-0007.inprogress
2024-06-10T20:19:56,778 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610201956-0007/0 is now RUNNING
2024-06-10T20:19:56,870 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610201956-0007/2 is now RUNNING
2024-06-10T20:19:57,041 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@67b12933{/,null,STOPPED,@Spark}
2024-06-10T20:19:57,043 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@602aa178{/jobs,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,044 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@64506f22{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,046 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4a6db401{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,047 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5db5d38b{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,059 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@48719f2c{/stages,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,061 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4280f8f5{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,063 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@37063e02{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,098 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@623948c7{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,103 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@55ee9d4c{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,106 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5b8f652c{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,110 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5bed39e1{/storage,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,112 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4b241745{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,114 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@45b8340a{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,117 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@505989d3{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,131 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@62124399{/environment,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,133 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2491d309{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,136 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@436fc04e{/executors,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,137 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@72e51ca{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,169 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@34fa09f{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,172 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@35e33d4c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,173 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@e591672{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,175 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@561a5272{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,212 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@9746e1{/static,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,214 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ef65307{/,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,229 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4bb96bf1{/api,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,231 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4ce996c8{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,233 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1aa4af5e{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,245 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@53c106c4{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T20:19:57,253 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T20:19:57,833 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610201956-0007/1 is now RUNNING
2024-06-10T20:24:59,402 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T20:25:00,311 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T20:25:00,311 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T20:25:00,312 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T20:25:00,339 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T20:25:00,340 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T20:25:00,341 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T20:25:00,341 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: yelp-data-json-to-parquet
2024-06-10T20:25:00,365 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T20:25:00,374 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T20:25:00,375 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T20:25:00,427 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T20:25:00,428 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T20:25:00,429 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T20:25:00,429 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T20:25:00,430 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T20:25:00,618 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 43661.
2024-06-10T20:25:00,646 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T20:25:00,681 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T20:25:00,702 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T20:25:00,704 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T20:25:00,711 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T20:25:00,740 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-faba136b-5990-4757-88ed-f44165f1077f
2024-06-10T20:25:00,759 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T20:25:00,779 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T20:25:00,822 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @2688ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T20:25:00,907 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T20:25:00,919 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T20:25:00,935 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @2802ms
2024-06-10T20:25:00,978 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@2d8a3d90{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T20:25:00,978 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T20:25:01,012 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2edbd2f6{/,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,028 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://601fd26cc72d:43661/jars/hadoop-aws-3.3.2.jar with timestamp 1718051100305
2024-06-10T20:25:01,028 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://601fd26cc72d:43661/jars/aws-java-sdk-1.12.367.jar with timestamp 1718051100305
2024-06-10T20:25:01,029 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://601fd26cc72d:43661/jars/s3-2.18.41.jar with timestamp 1718051100305
2024-06-10T20:25:01,029 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://601fd26cc72d:43661/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718051100305
2024-06-10T20:25:01,123 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T20:25:01,169 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.22.0.2:7077 after 24 ms (0 ms spent in bootstraps)
2024-06-10T20:25:01,262 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610202501-0008
2024-06-10T20:25:01,274 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610202501-0008/0 on worker-20240610173515-172.22.0.6-40655 (172.22.0.6:40655) with 2 core(s)
2024-06-10T20:25:01,277 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610202501-0008/0 on hostPort 172.22.0.6:40655 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:25:01,280 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610202501-0008/1 on worker-20240610173514-172.22.0.5-43309 (172.22.0.5:43309) with 2 core(s)
2024-06-10T20:25:01,281 [dispatcher-event-loop-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610202501-0008/1 on hostPort 172.22.0.5:43309 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:25:01,281 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610202501-0008/2 on worker-20240610173514-172.22.0.4-43383 (172.22.0.4:43383) with 2 core(s)
2024-06-10T20:25:01,283 [dispatcher-event-loop-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610202501-0008/2 on hostPort 172.22.0.4:43383 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:25:01,294 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39509.
2024-06-10T20:25:01,294 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 601fd26cc72d:39509
2024-06-10T20:25:01,297 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T20:25:01,310 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 601fd26cc72d, 39509, None)
2024-06-10T20:25:01,319 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 601fd26cc72d:39509 with 434.4 MiB RAM, BlockManagerId(driver, 601fd26cc72d, 39509, None)
2024-06-10T20:25:01,322 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 601fd26cc72d, 39509, None)
2024-06-10T20:25:01,326 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 601fd26cc72d, 39509, None)
2024-06-10T20:25:01,427 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610202501-0008/0 is now RUNNING
2024-06-10T20:25:01,431 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610202501-0008/2 is now RUNNING
2024-06-10T20:25:01,511 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610202501-0008/1 is now RUNNING
2024-06-10T20:25:01,521 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610202501-0008.inprogress
2024-06-10T20:25:01,817 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@2edbd2f6{/,null,STOPPED,@Spark}
2024-06-10T20:25:01,819 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6efe5013{/jobs,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,820 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3e63c104{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,849 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6b95580e{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,866 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@62cd218c{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,875 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1e6692c6{/stages,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,879 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1c73d0a{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,900 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@44662cd3{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,923 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4664d706{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,926 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6c49808e{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,928 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@485f1551{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,929 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@10c8f2b9{/storage,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,950 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@11026923{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,952 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5c79b76c{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,955 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@47c0da6a{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,958 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@43797b34{/environment,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,960 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@86c0eb5{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,974 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@149cd15{/executors,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,976 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5448a654{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,980 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1f7d3aee{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,988 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7aad0975{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,992 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@478dd3b6{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T20:25:01,998 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@d251bb6{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T20:25:02,022 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1cdcf236{/static,null,AVAILABLE,@Spark}
2024-06-10T20:25:02,027 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6da42aea{/,null,AVAILABLE,@Spark}
2024-06-10T20:25:02,034 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2953b260{/api,null,AVAILABLE,@Spark}
2024-06-10T20:25:02,037 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1f529c11{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T20:25:02,042 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5d316a3{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T20:25:02,055 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@49168fc8{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T20:25:02,059 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T20:26:23,876 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T20:26:24,736 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T20:26:24,736 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T20:26:24,737 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T20:26:24,760 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T20:26:24,761 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T20:26:24,762 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T20:26:24,762 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: yelp-data-json-to-parquet
2024-06-10T20:26:24,783 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T20:26:24,792 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T20:26:24,793 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T20:26:24,849 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T20:26:24,850 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T20:26:24,850 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T20:26:24,851 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T20:26:24,852 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T20:26:25,028 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 43533.
2024-06-10T20:26:25,057 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T20:26:25,096 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T20:26:25,118 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T20:26:25,119 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T20:26:25,123 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T20:26:25,149 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-445fa303-e7cd-4847-818e-0d00e75e27dd
2024-06-10T20:26:25,164 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T20:26:25,184 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T20:26:25,225 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @2599ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T20:26:25,305 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T20:26:25,316 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T20:26:25,336 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @2710ms
2024-06-10T20:26:25,381 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@2d8a3d90{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T20:26:25,381 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T20:26:25,402 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2edbd2f6{/,null,AVAILABLE,@Spark}
2024-06-10T20:26:25,418 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://601fd26cc72d:43533/jars/hadoop-aws-3.3.2.jar with timestamp 1718051184730
2024-06-10T20:26:25,419 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://601fd26cc72d:43533/jars/aws-java-sdk-1.12.367.jar with timestamp 1718051184730
2024-06-10T20:26:25,419 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://601fd26cc72d:43533/jars/s3-2.18.41.jar with timestamp 1718051184730
2024-06-10T20:26:25,420 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://601fd26cc72d:43533/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718051184730
2024-06-10T20:26:25,499 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T20:26:25,545 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.22.0.2:7077 after 26 ms (0 ms spent in bootstraps)
2024-06-10T20:26:25,637 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610202625-0009
2024-06-10T20:26:25,641 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610202625-0009/0 on worker-20240610173515-172.22.0.6-40655 (172.22.0.6:40655) with 2 core(s)
2024-06-10T20:26:25,647 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610202625-0009/0 on hostPort 172.22.0.6:40655 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:26:25,648 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610202625-0009/1 on worker-20240610173514-172.22.0.5-43309 (172.22.0.5:43309) with 2 core(s)
2024-06-10T20:26:25,650 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610202625-0009/1 on hostPort 172.22.0.5:43309 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:26:25,650 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610202625-0009/2 on worker-20240610173514-172.22.0.4-43383 (172.22.0.4:43383) with 2 core(s)
2024-06-10T20:26:25,651 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610202625-0009/2 on hostPort 172.22.0.4:43383 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:26:25,662 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44953.
2024-06-10T20:26:25,663 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 601fd26cc72d:44953
2024-06-10T20:26:25,668 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T20:26:25,689 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 601fd26cc72d, 44953, None)
2024-06-10T20:26:25,696 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 601fd26cc72d:44953 with 434.4 MiB RAM, BlockManagerId(driver, 601fd26cc72d, 44953, None)
2024-06-10T20:26:25,702 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 601fd26cc72d, 44953, None)
2024-06-10T20:26:25,704 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 601fd26cc72d, 44953, None)
2024-06-10T20:26:25,773 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610202625-0009/1 is now RUNNING
2024-06-10T20:26:25,797 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610202625-0009/0 is now RUNNING
2024-06-10T20:26:25,822 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610202625-0009/2 is now RUNNING
2024-06-10T20:26:25,916 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610202625-0009.inprogress
2024-06-10T20:26:26,157 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@2edbd2f6{/,null,STOPPED,@Spark}
2024-06-10T20:26:26,172 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6efe5013{/jobs,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,175 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3e63c104{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,177 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6b95580e{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,179 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@62cd218c{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,181 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1e6692c6{/stages,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,183 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1c73d0a{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,195 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@44662cd3{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,197 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4664d706{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,200 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6c49808e{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,202 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@485f1551{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,224 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@10c8f2b9{/storage,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,226 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@11026923{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,228 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5c79b76c{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,230 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@47c0da6a{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,233 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@43797b34{/environment,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,244 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@86c0eb5{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,248 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@149cd15{/executors,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,265 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5448a654{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,267 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1f7d3aee{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,269 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7aad0975{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,272 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@478dd3b6{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,274 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@d251bb6{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,305 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1cdcf236{/static,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,310 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6da42aea{/,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,321 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2953b260{/api,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,325 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1f529c11{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,328 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5d316a3{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,359 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@49168fc8{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T20:26:26,361 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T20:26:29,919 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-10T20:32:12,463 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T20:32:13,716 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T20:32:13,717 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T20:32:13,717 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T20:32:13,743 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T20:32:13,744 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T20:32:13,744 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T20:32:13,746 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: yelp-data-json-to-parquet
2024-06-10T20:32:13,768 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T20:32:13,777 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T20:32:13,778 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T20:32:13,830 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T20:32:13,831 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T20:32:13,832 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T20:32:13,832 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T20:32:13,833 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T20:32:14,017 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 42153.
2024-06-10T20:32:14,046 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T20:32:14,085 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T20:32:14,112 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T20:32:14,113 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T20:32:14,118 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T20:32:14,146 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-cf4faa4e-7a4a-40f1-aaeb-73e2df15c54b
2024-06-10T20:32:14,161 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T20:32:14,181 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T20:32:14,224 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3311ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T20:32:14,310 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T20:32:14,322 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T20:32:14,343 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @3431ms
2024-06-10T20:32:14,393 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@13f48729{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T20:32:14,394 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T20:32:14,418 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5283d231{/,null,AVAILABLE,@Spark}
2024-06-10T20:32:14,435 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://601fd26cc72d:42153/jars/hadoop-aws-3.3.2.jar with timestamp 1718051533710
2024-06-10T20:32:14,435 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://601fd26cc72d:42153/jars/aws-java-sdk-1.12.367.jar with timestamp 1718051533710
2024-06-10T20:32:14,436 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://601fd26cc72d:42153/jars/s3-2.18.41.jar with timestamp 1718051533710
2024-06-10T20:32:14,436 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://601fd26cc72d:42153/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718051533710
2024-06-10T20:32:14,524 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T20:32:14,575 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.22.0.2:7077 after 30 ms (0 ms spent in bootstraps)
2024-06-10T20:32:14,671 [dispatcher-event-loop-0] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610203214-0010
2024-06-10T20:32:14,688 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40793.
2024-06-10T20:32:14,689 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610203214-0010/0 on worker-20240610173515-172.22.0.6-40655 (172.22.0.6:40655) with 2 core(s)
2024-06-10T20:32:14,689 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 601fd26cc72d:40793
2024-06-10T20:32:14,694 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T20:32:14,694 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610203214-0010/0 on hostPort 172.22.0.6:40655 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:32:14,701 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610203214-0010/1 on worker-20240610173514-172.22.0.5-43309 (172.22.0.5:43309) with 2 core(s)
2024-06-10T20:32:14,702 [dispatcher-event-loop-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610203214-0010/1 on hostPort 172.22.0.5:43309 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:32:14,706 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610203214-0010/2 on worker-20240610173514-172.22.0.4-43383 (172.22.0.4:43383) with 2 core(s)
2024-06-10T20:32:14,708 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610203214-0010/2 on hostPort 172.22.0.4:43383 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:32:14,715 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 601fd26cc72d, 40793, None)
2024-06-10T20:32:14,722 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 601fd26cc72d:40793 with 434.4 MiB RAM, BlockManagerId(driver, 601fd26cc72d, 40793, None)
2024-06-10T20:32:14,727 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 601fd26cc72d, 40793, None)
2024-06-10T20:32:14,732 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 601fd26cc72d, 40793, None)
2024-06-10T20:32:14,825 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610203214-0010/1 is now RUNNING
2024-06-10T20:32:14,854 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610203214-0010/0 is now RUNNING
2024-06-10T20:32:14,900 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610203214-0010/2 is now RUNNING
2024-06-10T20:32:14,998 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610203214-0010.inprogress
2024-06-10T20:32:15,574 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@5283d231{/,null,STOPPED,@Spark}
2024-06-10T20:32:15,586 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1847fb72{/jobs,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,598 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ee1af97{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,600 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3fb5b776{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,607 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@47b6f381{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,609 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30b7ac12{/stages,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,611 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@16fa06e2{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,628 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@185c11b5{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,630 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@945d51{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,632 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@77a899a8{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,633 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@736618ee{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,659 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4033778b{/storage,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,669 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7250f8f{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,688 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1e5187a{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,691 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@54da4c1c{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,693 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2aaf66aa{/environment,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,696 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@34cbd6e5{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,730 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6264f111{/executors,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,734 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4b93b16{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,747 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@8294cba{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,751 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@569fd968{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,767 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f594315{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,774 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@75108119{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,840 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@41363418{/static,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,848 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@58e4e569{/,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,869 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7f3296e4{/api,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,884 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2455b2c7{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,890 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4694af3b{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,909 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@164030a8{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T20:32:15,912 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T20:32:18,099 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-10T20:32:40,164 [Thread-5] WARN  org.apache.spark.sql.catalyst.util.SparkStringUtils [] - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2024-06-10T20:36:11,625 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-10T20:36:12,667 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-10T20:36:12,668 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-10T20:36:12,668 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-10T20:36:12,700 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T20:36:12,702 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-10T20:36:12,703 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-10T20:36:12,705 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: yelp-data-json-to-parquet
2024-06-10T20:36:12,736 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-10T20:36:12,748 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-10T20:36:12,750 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-10T20:36:12,825 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-10T20:36:12,826 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-10T20:36:12,826 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-10T20:36:12,827 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-10T20:36:12,827 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-10T20:36:13,050 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 35449.
2024-06-10T20:36:13,079 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-10T20:36:13,123 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-10T20:36:13,146 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-10T20:36:13,147 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-10T20:36:13,152 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-10T20:36:13,181 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-9950daaa-78dc-413b-a38d-b824130e745d
2024-06-10T20:36:13,213 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-10T20:36:13,240 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-10T20:36:13,289 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @2983ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-10T20:36:13,380 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-10T20:36:13,392 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-10T20:36:13,411 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @3105ms
2024-06-10T20:36:13,464 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@52644952{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-10T20:36:13,464 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-10T20:36:13,487 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2abf2fd8{/,null,AVAILABLE,@Spark}
2024-06-10T20:36:13,505 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://601fd26cc72d:35449/jars/hadoop-aws-3.3.2.jar with timestamp 1718051772661
2024-06-10T20:36:13,506 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://601fd26cc72d:35449/jars/aws-java-sdk-1.12.367.jar with timestamp 1718051772661
2024-06-10T20:36:13,506 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://601fd26cc72d:35449/jars/s3-2.18.41.jar with timestamp 1718051772661
2024-06-10T20:36:13,507 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://601fd26cc72d:35449/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718051772661
2024-06-10T20:36:13,605 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-10T20:36:13,658 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.22.0.2:7077 after 30 ms (0 ms spent in bootstraps)
2024-06-10T20:36:13,754 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240610203613-0011
2024-06-10T20:36:13,758 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610203613-0011/0 on worker-20240610173515-172.22.0.6-40655 (172.22.0.6:40655) with 2 core(s)
2024-06-10T20:36:13,763 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610203613-0011/0 on hostPort 172.22.0.6:40655 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:36:13,768 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610203613-0011/1 on worker-20240610173514-172.22.0.5-43309 (172.22.0.5:43309) with 2 core(s)
2024-06-10T20:36:13,771 [dispatcher-event-loop-0] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610203613-0011/1 on hostPort 172.22.0.5:43309 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:36:13,776 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240610203613-0011/2 on worker-20240610173514-172.22.0.4-43383 (172.22.0.4:43383) with 2 core(s)
2024-06-10T20:36:13,779 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240610203613-0011/2 on hostPort 172.22.0.4:43383 with 2 core(s), 3.0 GiB RAM
2024-06-10T20:36:13,788 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36333.
2024-06-10T20:36:13,789 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 601fd26cc72d:36333
2024-06-10T20:36:13,794 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-10T20:36:13,819 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 601fd26cc72d, 36333, None)
2024-06-10T20:36:13,827 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 601fd26cc72d:36333 with 434.4 MiB RAM, BlockManagerId(driver, 601fd26cc72d, 36333, None)
2024-06-10T20:36:13,833 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 601fd26cc72d, 36333, None)
2024-06-10T20:36:13,836 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 601fd26cc72d, 36333, None)
2024-06-10T20:36:14,009 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610203613-0011/0 is now RUNNING
2024-06-10T20:36:14,010 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610203613-0011/1 is now RUNNING
2024-06-10T20:36:14,041 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240610203613-0011/2 is now RUNNING
2024-06-10T20:36:14,250 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240610203613-0011.inprogress
2024-06-10T20:36:14,564 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@2abf2fd8{/,null,STOPPED,@Spark}
2024-06-10T20:36:14,577 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30016d99{/jobs,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,578 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@77a56e86{/jobs/json,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,581 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@376e6c0d{/jobs/job,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,591 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3a682c7c{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,594 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@a4098f6{/stages,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,597 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ddc9fb3{/stages/json,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,599 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@27796956{/stages/stage,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,601 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@f219d12{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,603 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@49ed45{/stages/pool,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,605 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@b9c7f36{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,607 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@18e80c37{/storage,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,609 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4d5f9468{/storage/json,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,612 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@65f879fa{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,615 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6002a609{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,617 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@31d3a2cd{/environment,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,620 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@695274fa{/environment/json,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,623 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@430c44d3{/executors,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,625 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@87b996e{/executors/json,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,628 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6c6135ed{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,631 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6c968720{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,634 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@121e9d89{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,641 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@64f80ec4{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,667 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5d007952{/static,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,673 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1676b202{/,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,685 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@40e2a2a0{/api,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,688 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6650cab3{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,692 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3815eef4{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,709 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@71d0d6ea{/metrics/json,null,AVAILABLE,@Spark}
2024-06-10T20:36:14,726 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-10T20:36:17,449 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-10T20:36:37,047 [Thread-5] WARN  org.apache.spark.sql.catalyst.util.SparkStringUtils [] - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2024-06-11T12:15:57,384 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-11T12:15:58,806 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-11T12:15:58,807 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-11T12:15:58,808 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-11T12:15:58,843 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-11T12:15:58,844 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-11T12:15:58,844 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-11T12:15:58,845 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq-fine-tuning
2024-06-11T12:15:58,873 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-11T12:15:58,885 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-11T12:15:58,886 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-11T12:15:58,963 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-11T12:15:58,964 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-11T12:15:58,965 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-11T12:15:58,966 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-11T12:15:58,967 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-11T12:15:59,253 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 45421.
2024-06-11T12:15:59,333 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-11T12:15:59,411 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-11T12:15:59,440 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-11T12:15:59,443 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-11T12:15:59,449 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-11T12:15:59,493 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-467b7e55-f815-48bb-80e0-ac11e95b8bc8
2024-06-11T12:15:59,517 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-11T12:15:59,547 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-11T12:15:59,605 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @4008ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-11T12:15:59,747 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-11T12:15:59,765 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-11T12:15:59,798 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @4202ms
2024-06-11T12:15:59,861 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@13f48729{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-11T12:15:59,862 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-11T12:15:59,907 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5283d231{/,null,AVAILABLE,@Spark}
2024-06-11T12:15:59,927 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://68a3110d0260:45421/jars/hadoop-aws-3.3.2.jar with timestamp 1718108158799
2024-06-11T12:15:59,928 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://68a3110d0260:45421/jars/aws-java-sdk-1.12.367.jar with timestamp 1718108158799
2024-06-11T12:15:59,928 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://68a3110d0260:45421/jars/s3-2.18.41.jar with timestamp 1718108158799
2024-06-11T12:15:59,929 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://68a3110d0260:45421/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718108158799
2024-06-11T12:16:00,057 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-11T12:16:00,108 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.18.0.2:7077 after 27 ms (0 ms spent in bootstraps)
2024-06-11T12:16:00,270 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240611121600-0000
2024-06-11T12:16:00,287 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38393.
2024-06-11T12:16:00,287 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 68a3110d0260:38393
2024-06-11T12:16:00,297 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-11T12:16:00,311 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611121600-0000/0 on worker-20240611121455-172.18.0.5-36991 (172.18.0.5:36991) with 2 core(s)
2024-06-11T12:16:00,315 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611121600-0000/0 on hostPort 172.18.0.5:36991 with 2 core(s), 3.0 GiB RAM
2024-06-11T12:16:00,317 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611121600-0000/1 on worker-20240611121455-172.18.0.6-45533 (172.18.0.6:45533) with 2 core(s)
2024-06-11T12:16:00,318 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611121600-0000/1 on hostPort 172.18.0.6:45533 with 2 core(s), 3.0 GiB RAM
2024-06-11T12:16:00,339 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611121600-0000/2 on worker-20240611121455-172.18.0.4-40171 (172.18.0.4:40171) with 2 core(s)
2024-06-11T12:16:00,340 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611121600-0000/2 on hostPort 172.18.0.4:40171 with 2 core(s), 3.0 GiB RAM
2024-06-11T12:16:00,360 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 68a3110d0260, 38393, None)
2024-06-11T12:16:00,386 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 68a3110d0260:38393 with 434.4 MiB RAM, BlockManagerId(driver, 68a3110d0260, 38393, None)
2024-06-11T12:16:00,393 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 68a3110d0260, 38393, None)
2024-06-11T12:16:00,395 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 68a3110d0260, 38393, None)
2024-06-11T12:16:00,754 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240611121600-0000.inprogress
2024-06-11T12:16:00,761 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611121600-0000/2 is now RUNNING
2024-06-11T12:16:00,764 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611121600-0000/0 is now RUNNING
2024-06-11T12:16:00,767 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611121600-0000/1 is now RUNNING
2024-06-11T12:16:01,210 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@5283d231{/,null,STOPPED,@Spark}
2024-06-11T12:16:01,216 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1847fb72{/jobs,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,236 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ee1af97{/jobs/json,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,238 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3fb5b776{/jobs/job,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,240 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@47b6f381{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,248 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30b7ac12{/stages,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,252 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@16fa06e2{/stages/json,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,255 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@185c11b5{/stages/stage,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,258 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@945d51{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,262 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@77a899a8{/stages/pool,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,275 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@736618ee{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,278 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4033778b{/storage,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,281 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7250f8f{/storage/json,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,288 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1e5187a{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,290 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@54da4c1c{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,293 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2aaf66aa{/environment,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,300 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@34cbd6e5{/environment/json,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,306 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6264f111{/executors,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,309 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4b93b16{/executors/json,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,314 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@8294cba{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,320 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@569fd968{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,333 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f594315{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,337 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@75108119{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,362 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@41363418{/static,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,371 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@58e4e569{/,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,376 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7f3296e4{/api,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,380 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2455b2c7{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,389 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4694af3b{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,417 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@164030a8{/metrics/json,null,AVAILABLE,@Spark}
2024-06-11T12:16:01,425 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-11T12:16:05,223 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-11T12:33:51,846 [Thread-5] WARN  org.apache.spark.sql.catalyst.util.SparkStringUtils [] - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2024-06-11T12:33:51,872 [Thread-5] WARN  ch.cern.sparkmeasure.StageMetrics [] - Stage metrics data refreshed into temp view PerfStageMetrics
2024-06-11T12:33:52,618 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-11T12:33:54,556 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-11T12:40:06,820 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-11T12:40:08,021 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-11T12:40:08,022 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-11T12:40:08,022 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-11T12:40:08,050 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-11T12:40:08,051 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-11T12:40:08,052 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-11T12:40:08,055 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq-fine-tuning
2024-06-11T12:40:08,082 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-11T12:40:08,093 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-11T12:40:08,094 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-11T12:40:08,173 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-11T12:40:08,174 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-11T12:40:08,175 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-11T12:40:08,176 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-11T12:40:08,176 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-11T12:40:08,434 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 39649.
2024-06-11T12:40:08,479 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-11T12:40:08,531 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-11T12:40:08,561 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-11T12:40:08,561 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-11T12:40:08,566 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-11T12:40:08,591 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-6e68b42a-2a18-450a-8208-b2f8e1c228e1
2024-06-11T12:40:08,610 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-11T12:40:08,627 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-11T12:40:08,698 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3774ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-11T12:40:08,801 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-11T12:40:08,817 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-11T12:40:08,845 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @3922ms
2024-06-11T12:40:08,905 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@2d8a3d90{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-11T12:40:08,905 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-11T12:40:08,932 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2edbd2f6{/,null,AVAILABLE,@Spark}
2024-06-11T12:40:08,957 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://68a3110d0260:39649/jars/hadoop-aws-3.3.2.jar with timestamp 1718109608014
2024-06-11T12:40:08,958 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://68a3110d0260:39649/jars/aws-java-sdk-1.12.367.jar with timestamp 1718109608014
2024-06-11T12:40:08,958 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://68a3110d0260:39649/jars/s3-2.18.41.jar with timestamp 1718109608014
2024-06-11T12:40:08,958 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://68a3110d0260:39649/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718109608014
2024-06-11T12:40:09,058 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-11T12:40:09,113 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.18.0.2:7077 after 31 ms (0 ms spent in bootstraps)
2024-06-11T12:40:09,247 [dispatcher-event-loop-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240611124009-0001
2024-06-11T12:40:09,254 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41159.
2024-06-11T12:40:09,254 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 68a3110d0260:41159
2024-06-11T12:40:09,257 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-11T12:40:09,274 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 68a3110d0260, 41159, None)
2024-06-11T12:40:09,280 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 68a3110d0260:41159 with 434.4 MiB RAM, BlockManagerId(driver, 68a3110d0260, 41159, None)
2024-06-11T12:40:09,309 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611124009-0001/0 on worker-20240611121455-172.18.0.5-36991 (172.18.0.5:36991) with 2 core(s)
2024-06-11T12:40:09,317 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611124009-0001/0 on hostPort 172.18.0.5:36991 with 2 core(s), 3.0 GiB RAM
2024-06-11T12:40:09,319 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611124009-0001/1 on worker-20240611121455-172.18.0.6-45533 (172.18.0.6:45533) with 2 core(s)
2024-06-11T12:40:09,322 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 68a3110d0260, 41159, None)
2024-06-11T12:40:09,321 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611124009-0001/1 on hostPort 172.18.0.6:45533 with 2 core(s), 3.0 GiB RAM
2024-06-11T12:40:09,330 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 68a3110d0260, 41159, None)
2024-06-11T12:40:09,332 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611124009-0001/2 on worker-20240611121455-172.18.0.4-40171 (172.18.0.4:40171) with 2 core(s)
2024-06-11T12:40:09,334 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611124009-0001/2 on hostPort 172.18.0.4:40171 with 2 core(s), 3.0 GiB RAM
2024-06-11T12:40:09,581 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240611124009-0001.inprogress
2024-06-11T12:40:09,730 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@2edbd2f6{/,null,STOPPED,@Spark}
2024-06-11T12:40:09,732 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6efe5013{/jobs,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,734 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3e63c104{/jobs/json,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,736 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6b95580e{/jobs/job,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,738 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@62cd218c{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,740 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1e6692c6{/stages,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,741 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1c73d0a{/stages/json,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,745 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@44662cd3{/stages/stage,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,747 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4664d706{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,751 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6c49808e{/stages/pool,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,754 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@485f1551{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,762 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@10c8f2b9{/storage,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,767 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@11026923{/storage/json,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,769 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5c79b76c{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,772 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@47c0da6a{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,779 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@43797b34{/environment,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,787 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@86c0eb5{/environment/json,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,789 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@149cd15{/executors,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,791 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5448a654{/executors/json,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,794 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1f7d3aee{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,797 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7aad0975{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,804 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@478dd3b6{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,812 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@d251bb6{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,841 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1cdcf236{/static,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,843 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6da42aea{/,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,852 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2953b260{/api,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,858 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1f529c11{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,865 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5d316a3{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,881 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@49168fc8{/metrics/json,null,AVAILABLE,@Spark}
2024-06-11T12:40:09,885 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-11T12:40:09,993 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611124009-0001/2 is now RUNNING
2024-06-11T12:40:09,997 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611124009-0001/0 is now RUNNING
2024-06-11T12:40:10,073 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611124009-0001/1 is now RUNNING
2024-06-11T12:40:12,992 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-11T12:58:15,249 [Thread-5] WARN  org.apache.spark.sql.catalyst.util.SparkStringUtils [] - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2024-06-11T12:58:15,256 [Thread-5] WARN  ch.cern.sparkmeasure.StageMetrics [] - Stage metrics data refreshed into temp view PerfStageMetrics
2024-06-11T12:58:15,799 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-11T12:58:17,786 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-11T12:59:17,697 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-11T12:59:18,873 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-11T12:59:18,874 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-11T12:59:18,874 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-11T12:59:18,906 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-11T12:59:18,907 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-11T12:59:18,907 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-11T12:59:18,908 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq-fine-tuning
2024-06-11T12:59:18,936 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-11T12:59:18,945 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-11T12:59:18,946 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-11T12:59:19,023 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-11T12:59:19,024 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-11T12:59:19,025 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-11T12:59:19,025 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-11T12:59:19,026 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-11T12:59:19,282 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 40807.
2024-06-11T12:59:19,331 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-11T12:59:19,393 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-11T12:59:19,430 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-11T12:59:19,432 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-11T12:59:19,437 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-11T12:59:19,473 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-a859f266-d9d9-42d1-88ed-f21938463f73
2024-06-11T12:59:19,497 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-11T12:59:19,519 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-11T12:59:19,591 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3973ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-11T12:59:19,704 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-11T12:59:19,723 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-11T12:59:19,753 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @4136ms
2024-06-11T12:59:19,813 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@2d8a3d90{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-11T12:59:19,813 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-11T12:59:19,849 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2edbd2f6{/,null,AVAILABLE,@Spark}
2024-06-11T12:59:19,869 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://68a3110d0260:40807/jars/hadoop-aws-3.3.2.jar with timestamp 1718110758866
2024-06-11T12:59:19,869 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://68a3110d0260:40807/jars/aws-java-sdk-1.12.367.jar with timestamp 1718110758866
2024-06-11T12:59:19,869 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://68a3110d0260:40807/jars/s3-2.18.41.jar with timestamp 1718110758866
2024-06-11T12:59:19,870 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://68a3110d0260:40807/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718110758866
2024-06-11T12:59:19,968 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-11T12:59:20,027 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.18.0.2:7077 after 35 ms (0 ms spent in bootstraps)
2024-06-11T12:59:20,155 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240611125920-0002
2024-06-11T12:59:20,164 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40595.
2024-06-11T12:59:20,165 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 68a3110d0260:40595
2024-06-11T12:59:20,167 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-11T12:59:20,176 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 68a3110d0260, 40595, None)
2024-06-11T12:59:20,180 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 68a3110d0260:40595 with 434.4 MiB RAM, BlockManagerId(driver, 68a3110d0260, 40595, None)
2024-06-11T12:59:20,185 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 68a3110d0260, 40595, None)
2024-06-11T12:59:20,190 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 68a3110d0260, 40595, None)
2024-06-11T12:59:20,190 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611125920-0002/0 on worker-20240611121455-172.18.0.5-36991 (172.18.0.5:36991) with 2 core(s)
2024-06-11T12:59:20,194 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611125920-0002/0 on hostPort 172.18.0.5:36991 with 2 core(s), 3.0 GiB RAM
2024-06-11T12:59:20,195 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611125920-0002/1 on worker-20240611121455-172.18.0.6-45533 (172.18.0.6:45533) with 2 core(s)
2024-06-11T12:59:20,195 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611125920-0002/1 on hostPort 172.18.0.6:45533 with 2 core(s), 3.0 GiB RAM
2024-06-11T12:59:20,196 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611125920-0002/2 on worker-20240611121455-172.18.0.4-40171 (172.18.0.4:40171) with 2 core(s)
2024-06-11T12:59:20,199 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611125920-0002/2 on hostPort 172.18.0.4:40171 with 2 core(s), 3.0 GiB RAM
2024-06-11T12:59:20,379 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240611125920-0002.inprogress
2024-06-11T12:59:20,538 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@2edbd2f6{/,null,STOPPED,@Spark}
2024-06-11T12:59:20,540 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6efe5013{/jobs,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,542 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3e63c104{/jobs/json,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,545 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6b95580e{/jobs/job,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,547 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@62cd218c{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,549 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1e6692c6{/stages,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,551 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1c73d0a{/stages/json,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,554 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@44662cd3{/stages/stage,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,558 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4664d706{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,563 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6c49808e{/stages/pool,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,565 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@485f1551{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,574 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@10c8f2b9{/storage,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,576 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@11026923{/storage/json,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,579 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5c79b76c{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,581 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@47c0da6a{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,584 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@43797b34{/environment,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,588 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@86c0eb5{/environment/json,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,592 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@149cd15{/executors,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,594 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5448a654{/executors/json,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,597 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1f7d3aee{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,599 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7aad0975{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,603 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@478dd3b6{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,607 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@d251bb6{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,624 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1cdcf236{/static,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,627 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6da42aea{/,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,630 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2953b260{/api,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,632 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1f529c11{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,634 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5d316a3{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,646 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@49168fc8{/metrics/json,null,AVAILABLE,@Spark}
2024-06-11T12:59:20,648 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-11T12:59:20,816 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611125920-0002/0 is now RUNNING
2024-06-11T12:59:20,817 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611125920-0002/1 is now RUNNING
2024-06-11T12:59:20,819 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611125920-0002/2 is now RUNNING
2024-06-11T12:59:23,604 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-11T13:17:08,003 [Thread-5] WARN  org.apache.spark.sql.catalyst.util.SparkStringUtils [] - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2024-06-11T13:17:08,070 [Thread-5] WARN  ch.cern.sparkmeasure.StageMetrics [] - Stage metrics data refreshed into temp view PerfStageMetrics
2024-06-11T13:17:08,529 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-11T13:17:09,850 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-11T13:19:01,843 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-11T13:19:03,045 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-11T13:19:03,046 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-11T13:19:03,047 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-11T13:19:03,075 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-11T13:19:03,076 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-11T13:19:03,077 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-11T13:19:03,078 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq-fine-tuning
2024-06-11T13:19:03,104 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-11T13:19:03,113 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-11T13:19:03,115 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-11T13:19:03,187 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-11T13:19:03,188 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-11T13:19:03,188 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-11T13:19:03,189 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-11T13:19:03,189 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-11T13:19:03,442 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 36083.
2024-06-11T13:19:03,484 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-11T13:19:03,533 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-11T13:19:03,565 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-11T13:19:03,567 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-11T13:19:03,571 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-11T13:19:03,595 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-dcdc2180-1008-444a-964b-8c184d6a6afc
2024-06-11T13:19:03,615 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-11T13:19:03,633 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-11T13:19:03,698 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3848ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-11T13:19:03,801 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-11T13:19:03,815 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-11T13:19:03,844 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @3994ms
2024-06-11T13:19:03,898 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@70a0c394{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-11T13:19:03,898 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-11T13:19:03,931 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@310b4561{/,null,AVAILABLE,@Spark}
2024-06-11T13:19:03,949 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://68a3110d0260:36083/jars/hadoop-aws-3.3.2.jar with timestamp 1718111943038
2024-06-11T13:19:03,950 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://68a3110d0260:36083/jars/aws-java-sdk-1.12.367.jar with timestamp 1718111943038
2024-06-11T13:19:03,950 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://68a3110d0260:36083/jars/s3-2.18.41.jar with timestamp 1718111943038
2024-06-11T13:19:03,950 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://68a3110d0260:36083/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718111943038
2024-06-11T13:19:04,053 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-11T13:19:04,114 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.18.0.2:7077 after 33 ms (0 ms spent in bootstraps)
2024-06-11T13:19:04,230 [dispatcher-event-loop-0] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240611131904-0003
2024-06-11T13:19:04,238 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37873.
2024-06-11T13:19:04,238 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 68a3110d0260:37873
2024-06-11T13:19:04,240 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-11T13:19:04,250 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 68a3110d0260, 37873, None)
2024-06-11T13:19:04,256 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611131904-0003/0 on worker-20240611121455-172.18.0.5-36991 (172.18.0.5:36991) with 2 core(s)
2024-06-11T13:19:04,259 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 68a3110d0260:37873 with 434.4 MiB RAM, BlockManagerId(driver, 68a3110d0260, 37873, None)
2024-06-11T13:19:04,261 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611131904-0003/0 on hostPort 172.18.0.5:36991 with 2 core(s), 3.0 GiB RAM
2024-06-11T13:19:04,263 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611131904-0003/1 on worker-20240611121455-172.18.0.6-45533 (172.18.0.6:45533) with 2 core(s)
2024-06-11T13:19:04,265 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611131904-0003/1 on hostPort 172.18.0.6:45533 with 2 core(s), 3.0 GiB RAM
2024-06-11T13:19:04,265 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 68a3110d0260, 37873, None)
2024-06-11T13:19:04,265 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611131904-0003/2 on worker-20240611121455-172.18.0.4-40171 (172.18.0.4:40171) with 2 core(s)
2024-06-11T13:19:04,266 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611131904-0003/2 on hostPort 172.18.0.4:40171 with 2 core(s), 3.0 GiB RAM
2024-06-11T13:19:04,267 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 68a3110d0260, 37873, None)
2024-06-11T13:19:04,432 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240611131904-0003.inprogress
2024-06-11T13:19:04,585 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@310b4561{/,null,STOPPED,@Spark}
2024-06-11T13:19:04,586 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6dd36892{/jobs,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,588 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2de9c347{/jobs/json,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,589 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3cab3a63{/jobs/job,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,591 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@41c2f078{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,593 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@22abb136{/stages,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,595 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@66a0cb4c{/stages/json,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,597 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@12a3a730{/stages/stage,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,599 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2060da8a{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,600 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@f81e054{/stages/pool,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,602 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@51baa95d{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,604 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7365d596{/storage,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,608 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@44c7de91{/storage/json,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,609 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5a31b398{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,611 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7b2c7d81{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,613 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3a0986c{/environment,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,615 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@32f7c60b{/environment/json,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,617 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@332f5be8{/executors,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,619 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6e2fb4c8{/executors/json,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,624 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4d00c072{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,627 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1bb33083{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,629 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1d578099{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,631 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5dec4755{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,649 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5462846a{/static,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,651 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@31c72fe8{/,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,656 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6b850d98{/api,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,659 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2b6163b9{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,662 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7b036245{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,672 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3dec609a{/metrics/json,null,AVAILABLE,@Spark}
2024-06-11T13:19:04,675 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-11T13:19:04,831 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611131904-0003/1 is now RUNNING
2024-06-11T13:19:04,900 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611131904-0003/0 is now RUNNING
2024-06-11T13:19:05,038 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611131904-0003/2 is now RUNNING
2024-06-11T13:19:08,646 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-11T13:19:33,594 [Thread-5] WARN  org.apache.spark.sql.catalyst.analysis.HintErrorLogger [] - Count not find relation 'zones' specified in hint 'BROADCASTJOIN(zones)'.
2024-06-11T13:22:32,865 [Thread-5] ERROR org.apache.spark.sql.delta.files.DeltaFileFormatWriter [] - Aborting job c971cf32-431a-40db-b348-b8f394667ed2.
org.apache.spark.SparkException: Job 7 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:1253) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:1251) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:1251) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:3087) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$stop$3(DAGScheduler.scala:2973) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2973) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.SparkContext.$anonfun$stop$12(SparkContext.scala:2263) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1375) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2263) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2216) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.SparkContext.$anonfun$new$34(SparkContext.scala:686) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]
	at scala.util.Try$.apply(Try.scala:213) ~[scala-library-2.12.18.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398) ~[spark-core_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.delta.files.DeltaFileFormatWriter$.$anonfun$executeWrite$1(DeltaFileFormatWriter.scala:263) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.files.DeltaFileFormatWriter$.writeAndCommit(DeltaFileFormatWriter.scala:295) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.files.DeltaFileFormatWriter$.executeWrite(DeltaFileFormatWriter.scala:234) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.files.DeltaFileFormatWriter$.write(DeltaFileFormatWriter.scala:214) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.files.TransactionalWrite.$anonfun$writeFiles$1(TransactionalWrite.scala:440) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.delta.files.TransactionalWrite.writeFiles(TransactionalWrite.scala:398) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.files.TransactionalWrite.writeFiles$(TransactionalWrite.scala:371) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.OptimisticTransaction.writeFiles(OptimisticTransaction.scala:147) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.files.TransactionalWrite.writeFiles(TransactionalWrite.scala:246) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.files.TransactionalWrite.writeFiles$(TransactionalWrite.scala:242) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.OptimisticTransaction.writeFiles(OptimisticTransaction.scala:147) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.files.TransactionalWrite.writeFiles(TransactionalWrite.scala:235) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.files.TransactionalWrite.writeFiles$(TransactionalWrite.scala:232) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.OptimisticTransaction.writeFiles(OptimisticTransaction.scala:147) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.writeFiles(WriteIntoDelta.scala:349) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.writeAndReturnCommitData(WriteIntoDelta.scala:312) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.$anonfun$run$1(WriteIntoDelta.scala:106) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.$anonfun$run$1$adapted(WriteIntoDelta.scala:101) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.DeltaLog.withNewTransaction(DeltaLog.scala:227) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.commands.WriteIntoDelta.run(WriteIntoDelta.scala:101) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:201) ~[delta-spark_2.12-3.2.0.jar:3.2.0]
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461) ~[spark-catalyst_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76) [spark-sql-api_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461) [spark-catalyst_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32) [spark-catalyst_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) [spark-catalyst_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) [spark-catalyst_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) [spark-catalyst_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32) [spark-catalyst_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437) [spark-catalyst_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98) [spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85) [spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83) [spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142) [spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859) [spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388) [spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:304) [spark-sql_2.12-3.5.1.jar:3.5.1]
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240) [spark-sql_2.12-3.5.1.jar:3.5.1]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) [py4j-0.10.9.7.jar:?]
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374) [py4j-0.10.9.7.jar:?]
	at py4j.Gateway.invoke(Gateway.java:282) [py4j-0.10.9.7.jar:?]
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) [py4j-0.10.9.7.jar:?]
	at py4j.commands.CallCommand.execute(CallCommand.java:79) [py4j-0.10.9.7.jar:?]
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182) [py4j-0.10.9.7.jar:?]
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106) [py4j-0.10.9.7.jar:?]
	at java.lang.Thread.run(Thread.java:840) [?:?]
2024-06-11T13:23:04,998 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-11T13:23:06,173 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-11T13:23:06,174 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-11T13:23:06,174 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-11T13:23:06,207 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-11T13:23:06,208 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-11T13:23:06,208 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-11T13:23:06,209 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq-fine-tuning
2024-06-11T13:23:06,239 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-11T13:23:06,248 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-11T13:23:06,250 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-11T13:23:06,331 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-11T13:23:06,333 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-11T13:23:06,333 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-11T13:23:06,334 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-11T13:23:06,334 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-11T13:23:06,596 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 43947.
2024-06-11T13:23:06,648 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-11T13:23:06,705 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-11T13:23:06,733 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-11T13:23:06,735 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-11T13:23:06,741 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-11T13:23:06,777 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-086ec92f-e59b-4247-847f-7b1fc976c567
2024-06-11T13:23:06,794 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-11T13:23:06,814 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-11T13:23:06,883 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3948ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-11T13:23:06,986 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-11T13:23:07,000 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-11T13:23:07,026 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @4091ms
2024-06-11T13:23:07,087 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@380aefb9{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-11T13:23:07,087 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-11T13:23:07,113 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3116923c{/,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,134 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://68a3110d0260:43947/jars/hadoop-aws-3.3.2.jar with timestamp 1718112186166
2024-06-11T13:23:07,136 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://68a3110d0260:43947/jars/aws-java-sdk-1.12.367.jar with timestamp 1718112186166
2024-06-11T13:23:07,137 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://68a3110d0260:43947/jars/s3-2.18.41.jar with timestamp 1718112186166
2024-06-11T13:23:07,138 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://68a3110d0260:43947/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718112186166
2024-06-11T13:23:07,236 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-11T13:23:07,286 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.18.0.2:7077 after 28 ms (0 ms spent in bootstraps)
2024-06-11T13:23:07,400 [dispatcher-event-loop-2] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240611132307-0004
2024-06-11T13:23:07,409 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44933.
2024-06-11T13:23:07,410 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 68a3110d0260:44933
2024-06-11T13:23:07,412 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-11T13:23:07,424 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611132307-0004/0 on worker-20240611121455-172.18.0.5-36991 (172.18.0.5:36991) with 2 core(s)
2024-06-11T13:23:07,425 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 68a3110d0260, 44933, None)
2024-06-11T13:23:07,428 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611132307-0004/0 on hostPort 172.18.0.5:36991 with 2 core(s), 3.0 GiB RAM
2024-06-11T13:23:07,429 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611132307-0004/1 on worker-20240611121455-172.18.0.6-45533 (172.18.0.6:45533) with 2 core(s)
2024-06-11T13:23:07,431 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611132307-0004/1 on hostPort 172.18.0.6:45533 with 2 core(s), 3.0 GiB RAM
2024-06-11T13:23:07,432 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 68a3110d0260:44933 with 434.4 MiB RAM, BlockManagerId(driver, 68a3110d0260, 44933, None)
2024-06-11T13:23:07,435 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611132307-0004/2 on worker-20240611121455-172.18.0.4-40171 (172.18.0.4:40171) with 2 core(s)
2024-06-11T13:23:07,436 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 68a3110d0260, 44933, None)
2024-06-11T13:23:07,436 [dispatcher-event-loop-1] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611132307-0004/2 on hostPort 172.18.0.4:40171 with 2 core(s), 3.0 GiB RAM
2024-06-11T13:23:07,439 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 68a3110d0260, 44933, None)
2024-06-11T13:23:07,686 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240611132307-0004.inprogress
2024-06-11T13:23:07,903 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@3116923c{/,null,STOPPED,@Spark}
2024-06-11T13:23:07,910 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@58acef7c{/jobs,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,913 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@167aa6de{/jobs/json,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,916 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2da3e7e8{/jobs/job,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,919 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5495a8f4{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,921 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6f1be372{/stages,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,925 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@315a5cde{/stages/json,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,933 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@667aed9e{/stages/stage,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,936 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7d8b6362{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,938 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@531e5f03{/stages/pool,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,944 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@73d864e0{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,950 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7a48cf19{/storage,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,954 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6ba2b918{/storage/json,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,958 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7728293f{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,962 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3bac3fdc{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,967 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@660e2336{/environment,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,970 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@389ad2d8{/environment/json,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,974 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3311533e{/executors,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,984 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2d8dc6e9{/executors/json,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,986 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3e9f6ab2{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,989 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@40b69491{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,992 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@706c1bb8{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-11T13:23:07,997 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7abf0934{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-11T13:23:08,021 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@463b22d2{/static,null,AVAILABLE,@Spark}
2024-06-11T13:23:08,024 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@422047ba{/,null,AVAILABLE,@Spark}
2024-06-11T13:23:08,032 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2ccce8cf{/api,null,AVAILABLE,@Spark}
2024-06-11T13:23:08,035 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7c5b2e1d{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-11T13:23:08,038 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@9a1ac99{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-11T13:23:08,055 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5d7a31f9{/metrics/json,null,AVAILABLE,@Spark}
2024-06-11T13:23:08,058 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-11T13:23:08,219 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611132307-0004/0 is now RUNNING
2024-06-11T13:23:08,330 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611132307-0004/1 is now RUNNING
2024-06-11T13:23:08,362 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611132307-0004/2 is now RUNNING
2024-06-11T13:23:12,567 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-11T13:41:47,394 [Thread-5] WARN  org.apache.spark.sql.catalyst.util.SparkStringUtils [] - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2024-06-11T13:41:47,400 [Thread-5] WARN  ch.cern.sparkmeasure.StageMetrics [] - Stage metrics data refreshed into temp view PerfStageMetrics
2024-06-11T13:41:47,927 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-11T13:41:49,256 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-11T13:46:18,159 [main] WARN  org.apache.hadoop.util.NativeCodeLoader [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-06-11T13:46:19,351 [Thread-5] INFO  org.apache.spark.SparkContext [] - Running Spark version 3.5.1
2024-06-11T13:46:19,352 [Thread-5] INFO  org.apache.spark.SparkContext [] - OS info Linux, 5.15.146.1-microsoft-standard-WSL2, amd64
2024-06-11T13:46:19,352 [Thread-5] INFO  org.apache.spark.SparkContext [] - Java version 17.0.11
2024-06-11T13:46:19,382 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-11T13:46:19,383 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - No custom resources configured for spark.driver.
2024-06-11T13:46:19,383 [Thread-5] INFO  org.apache.spark.resource.ResourceUtils [] - ==============================================================
2024-06-11T13:46:19,384 [Thread-5] INFO  org.apache.spark.SparkContext [] - Submitted application: elt-rides-fhvhv-py-strawberry-owshq-fine-tuning
2024-06-11T13:46:19,408 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 3072, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2024-06-11T13:46:19,417 [Thread-5] INFO  org.apache.spark.resource.ResourceProfile [] - Limiting resource is cpu
2024-06-11T13:46:19,418 [Thread-5] INFO  org.apache.spark.resource.ResourceProfileManager [] - Added ResourceProfile id: 0
2024-06-11T13:46:19,489 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls to: root,spark
2024-06-11T13:46:19,490 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls to: root,spark
2024-06-11T13:46:19,491 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing view acls groups to: 
2024-06-11T13:46:19,491 [Thread-5] INFO  org.apache.spark.SecurityManager [] - Changing modify acls groups to: 
2024-06-11T13:46:19,492 [Thread-5] INFO  org.apache.spark.SecurityManager [] - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
2024-06-11T13:46:19,736 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'sparkDriver' on port 46145.
2024-06-11T13:46:19,802 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering MapOutputTracker
2024-06-11T13:46:19,868 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMaster
2024-06-11T13:46:19,898 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2024-06-11T13:46:19,899 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - BlockManagerMasterEndpoint up
2024-06-11T13:46:19,903 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering BlockManagerMasterHeartbeat
2024-06-11T13:46:19,933 [Thread-5] INFO  org.apache.spark.storage.DiskBlockManager [] - Created local directory at /tmp/blockmgr-cdb01e7b-f0b8-4a77-b664-8aa72a049e45
2024-06-11T13:46:19,953 [Thread-5] INFO  org.apache.spark.storage.memory.MemoryStore [] - MemoryStore started with capacity 434.4 MiB
2024-06-11T13:46:19,976 [Thread-5] INFO  org.apache.spark.SparkEnv [] - Registering OutputCommitCoordinator
2024-06-11T13:46:20,041 [Thread-5] INFO  org.sparkproject.jetty.util.log [] - Logging initialized @3759ms to org.sparkproject.jetty.util.log.Slf4jLog
2024-06-11T13:46:20,139 [Thread-5] INFO  org.apache.spark.ui.JettyUtils [] - Start Jetty 0.0.0.0:4040 for SparkUI
2024-06-11T13:46:20,156 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 17.0.11+12-LTS
2024-06-11T13:46:20,184 [Thread-5] INFO  org.sparkproject.jetty.server.Server [] - Started @3904ms
2024-06-11T13:46:20,241 [Thread-5] INFO  org.sparkproject.jetty.server.AbstractConnector [] - Started ServerConnector@13f48729{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2024-06-11T13:46:20,242 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'SparkUI' on port 4040.
2024-06-11T13:46:20,269 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5283d231{/,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,295 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/hadoop-aws-3.3.2.jar at spark://68a3110d0260:46145/jars/hadoop-aws-3.3.2.jar with timestamp 1718113579344
2024-06-11T13:46:20,296 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-1.12.367.jar at spark://68a3110d0260:46145/jars/aws-java-sdk-1.12.367.jar with timestamp 1718113579344
2024-06-11T13:46:20,296 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/s3-2.18.41.jar at spark://68a3110d0260:46145/jars/s3-2.18.41.jar with timestamp 1718113579344
2024-06-11T13:46:20,296 [Thread-5] INFO  org.apache.spark.SparkContext [] - Added JAR file:///opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar at spark://68a3110d0260:46145/jars/aws-java-sdk-bundle-1.11.1026.jar with timestamp 1718113579344
2024-06-11T13:46:20,391 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Connecting to master spark://spark-master:7077...
2024-06-11T13:46:20,447 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory [] - Successfully created connection to spark-master/172.18.0.2:7077 after 30 ms (0 ms spent in bootstraps)
2024-06-11T13:46:20,572 [dispatcher-event-loop-4] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Connected to Spark cluster with app ID app-20240611134620-0005
2024-06-11T13:46:20,579 [Thread-5] INFO  org.apache.spark.util.Utils [] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45803.
2024-06-11T13:46:20,580 [Thread-5] INFO  org.apache.spark.network.netty.NettyBlockTransferService [] - Server created on 68a3110d0260:45803
2024-06-11T13:46:20,583 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2024-06-11T13:46:20,596 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registering BlockManager BlockManagerId(driver, 68a3110d0260, 45803, None)
2024-06-11T13:46:20,601 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint [] - Registering block manager 68a3110d0260:45803 with 434.4 MiB RAM, BlockManagerId(driver, 68a3110d0260, 45803, None)
2024-06-11T13:46:20,605 [Thread-5] INFO  org.apache.spark.storage.BlockManagerMaster [] - Registered BlockManager BlockManagerId(driver, 68a3110d0260, 45803, None)
2024-06-11T13:46:20,608 [Thread-5] INFO  org.apache.spark.storage.BlockManager [] - Initialized BlockManager: BlockManagerId(driver, 68a3110d0260, 45803, None)
2024-06-11T13:46:20,638 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611134620-0005/0 on worker-20240611121455-172.18.0.5-36991 (172.18.0.5:36991) with 2 core(s)
2024-06-11T13:46:20,642 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611134620-0005/0 on hostPort 172.18.0.5:36991 with 2 core(s), 3.0 GiB RAM
2024-06-11T13:46:20,643 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611134620-0005/1 on worker-20240611121455-172.18.0.6-45533 (172.18.0.6:45533) with 2 core(s)
2024-06-11T13:46:20,643 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611134620-0005/1 on hostPort 172.18.0.6:45533 with 2 core(s), 3.0 GiB RAM
2024-06-11T13:46:20,643 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor added: app-20240611134620-0005/2 on worker-20240611121455-172.18.0.4-40171 (172.18.0.4:40171) with 2 core(s)
2024-06-11T13:46:20,644 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - Granted executor ID app-20240611134620-0005/2 on hostPort 172.18.0.4:40171 with 2 core(s), 3.0 GiB RAM
2024-06-11T13:46:20,784 [Thread-5] INFO  org.apache.spark.deploy.history.SingleEventLogFileWriter [] - Logging events to file:/opt/bitnami/spark/logs/events/app-20240611134620-0005.inprogress
2024-06-11T13:46:20,950 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Stopped o.s.j.s.ServletContextHandler@5283d231{/,null,STOPPED,@Spark}
2024-06-11T13:46:20,952 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1847fb72{/jobs,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,955 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@ee1af97{/jobs/json,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,958 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@3fb5b776{/jobs/job,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,959 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@47b6f381{/jobs/job/json,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,962 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@30b7ac12{/stages,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,963 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@16fa06e2{/stages/json,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,967 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@185c11b5{/stages/stage,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,970 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@945d51{/stages/stage/json,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,972 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@77a899a8{/stages/pool,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,974 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@736618ee{/stages/pool/json,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,976 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4033778b{/storage,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,979 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7250f8f{/storage/json,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,980 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@1e5187a{/storage/rdd,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,982 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@54da4c1c{/storage/rdd/json,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,985 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2aaf66aa{/environment,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,987 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@34cbd6e5{/environment/json,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,989 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@6264f111{/executors,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,991 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4b93b16{/executors/json,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,993 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@8294cba{/executors/threadDump,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,995 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@569fd968{/executors/threadDump/json,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,997 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@5f594315{/executors/heapHistogram,null,AVAILABLE,@Spark}
2024-06-11T13:46:20,999 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@75108119{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2024-06-11T13:46:21,021 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@41363418{/static,null,AVAILABLE,@Spark}
2024-06-11T13:46:21,023 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@58e4e569{/,null,AVAILABLE,@Spark}
2024-06-11T13:46:21,027 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@7f3296e4{/api,null,AVAILABLE,@Spark}
2024-06-11T13:46:21,029 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@2455b2c7{/jobs/job/kill,null,AVAILABLE,@Spark}
2024-06-11T13:46:21,031 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@4694af3b{/stages/stage/kill,null,AVAILABLE,@Spark}
2024-06-11T13:46:21,044 [Thread-5] INFO  org.sparkproject.jetty.server.handler.ContextHandler [] - Started o.s.j.s.ServletContextHandler@164030a8{/metrics/json,null,AVAILABLE,@Spark}
2024-06-11T13:46:21,048 [Thread-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend [] - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-06-11T13:46:21,223 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611134620-0005/2 is now RUNNING
2024-06-11T13:46:21,226 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint [] - Executor updated: app-20240611134620-0005/0 is now RUNNING
2024-06-11T13:46:23,781 [Thread-5] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig [] - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2024-06-11T14:05:20,876 [Thread-5] WARN  org.apache.spark.sql.catalyst.util.SparkStringUtils [] - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2024-06-11T14:05:20,887 [Thread-5] WARN  ch.cern.sparkmeasure.StageMetrics [] - Stage metrics data refreshed into temp view PerfStageMetrics
2024-06-11T14:05:21,755 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
2024-06-11T14:05:23,345 [Thread-5] WARN  org.apache.hadoop.fs.s3a.commit.AbstractS3ACommitterFactory [] - Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.
